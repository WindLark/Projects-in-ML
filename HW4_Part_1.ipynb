{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Fm04hi-8pqE7",
        "ghEEe2IGijzj",
        "oE_-M5ErLIK_",
        "BMPZ_LyKbBCj",
        "hOPKQwDxTeEI",
        "w9h-HO5mTiwZ",
        "cFNDnQzFTqDj"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction\n",
        "\n",
        "[Colab Notebook Link](https://colab.research.google.com/drive/1OOQ2lUOtsObJvlZpjWRkdKLpi_xca-DO?usp=sharing)\n",
        "\n",
        "This time we'll perform classification on the basketball dataset using the Pytorch RNN.\n",
        "Our goal is to compare the efficiency of the base RNN, LSTM, and GRU with the \n",
        "feed-forward network that was implemented in part 3. We would like to see if \n",
        "any RNN is better at solving this problem than the feed forward network was.\n",
        "\n",
        "\n",
        "This time, my goal was to understand the Pytorch implementation of RNN, LSTM, and GRU, so I used the following documentation to help me implement my program:\n",
        "\n",
        "#Learning Pytorch RNN, LSTM, and GRU \n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "\n",
        "I studied the initial documentation to try and understand the the differences between the three models and their arguments. One initial point that interested me was that RNNs were able to take an argument for a desired activation function - in this case, I used ReLU (Rectified Linear Unit) to once again take gradient values and calculates max(0,z), effectively returning 0 for non positive values and 1 for positive values with the intention of addressing the vanishing gradient problem.  Similar to the previous homework, I used 2 layer networks.\n",
        "\n",
        "https://stats.stackexchange.com/questions/444923/activation-function-between-lstm-layers\n",
        "\n",
        "https://stackoverflow.com/questions/49040180/change-tanh-activation-in-lstm-to-relu\n",
        "\n",
        "https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be\n",
        "\n",
        "Implementations of LSTM and GRUs typically use sigmoid activation functions (LSTM also uses tanh activation functions), and it is generally assumed that this is the case for packages like Pytorch or Keras. One reason RelU might be viewed as an unfavorable activation function is can return large outputs, which could scale poorly for LSTMs trying to process data piece by piece.\n",
        "\n",
        "\n",
        "#Tutorials and Debugging\n",
        "\n",
        "https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
        "\n",
        "https://www.kaggle.com/code/namanmanchanda/rnn-in-pytorch/notebook\n",
        "\n",
        "https://www.kaggle.com/code/kanncaa1/recurrent-neural-network-with-pytorch/notebook\n",
        "\n",
        "https://stackoverflow.com/questions/64953102/how-can-i-use-an-lstm-to-classify-a-series-of-vectors-into-two-categories-in-pyt\n",
        "\n",
        "These tutorials were used to study the implementation of the aforementioned models and debug where necesssary. I struggled a lot with understanding how LSTM handled data, and as a result had to carefully review multiple tutorials until I realized that I was handling both hidden features and hidden layers incorrectly. In the interest of clarity, I have listed all tutorials I used during this debugging process.\n"
      ],
      "metadata": {
        "id": "edrFwygnOBw6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SjDlLtIMz0lg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wWyAKCsQ5UOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea1482d7-f633-4655-b170-03bf86a3e665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘Athlete_D’: File exists\n",
            "mkdir: cannot create directory ‘Athlete_Jc’: File exists\n",
            "mkdir: cannot create directory ‘Athlete_L’: File exists\n",
            "mkdir: cannot create directory ‘Athlete_X’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir Athlete_D\n",
        "!mkdir Athlete_Jc\n",
        "!mkdir Athlete_L\n",
        "!mkdir Athlete_X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Set and Base Requirements\n",
        "\n",
        "As mentioned above, this is the same dataset from part 3. We will be using it to compare the effectiveness of RNN vs feed-forward network for this problem.\n",
        "\n",
        "Dataset used https://archive.ics.uci.edu/ml/datasets/Basketball+dataset\n",
        "\n",
        "The data set is a Time Series dataset, where an athlete's acceleration and angle of acceleration change over the course of athlete's action (as time increases.)\n",
        "\n",
        "We will use accelerometer data to classify whether a basketball athlete is performing one of five actions in a basketball game: dribble, hold, pass, pickup, or shoot. We expect these classifications will be useful for sports analysts and coaches who are likely interested in whether their athletes are moving the correct way to perform the acting they intend (i.e. am athlete who intends to shoot should not be trying to pass!)\n",
        "\n",
        "The dataset consists of actions with the following 7 features:\n",
        "\n",
        "\n",
        "*   1:   Time - The time since the action has started, in seconds.\n",
        "\n",
        "*   2,3,4:   X,Y,Z - Acceleration of the athlete performing the action, as measured by an accelerometer in m/s^2.\n",
        "\n",
        "*   5:  R - Acceleration of the athlete as measured by a gyroscope in m/s^2.\n",
        "\n",
        "*   6,7: Theta, Phi - Angle of acceleration as measured by a gyroscope in  degrees.\n",
        "\n",
        "Additionally, \"dribble, hold, pass, pickup, or shoot\" will be assigned as the labels to this dataset, using numbers 0-4.\n",
        "\n",
        "The data was split among text files and organized by athlete initial and action taken. This setup was leveraged to quickly create a pandas dataframe that properly represented our data as seen in \"Loading Data and Peforming Exploratory Data Analysis\".\n",
        "\n"
      ],
      "metadata": {
        "id": "Fm04hi-8pqE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio torchdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fkfOKylaIRE",
        "outputId": "d7df2947-d037-47d6-96f1-ab24ef1806e5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.12.1+cu113)\n",
            "Collecting torchdata\n",
            "  Downloading torchdata-0.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Collecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 66.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.6.0 torchdata-0.4.1 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YMWVA4RuPIN5"
      },
      "outputs": [],
      "source": [
        "#import requirements\n",
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pytorch specific utils\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader , random_split, Dataset\n",
        "from torchtext import datasets\n",
        "from torchtext.transforms import ToTensor\n",
        "from torchtext.data import get_tokenizer\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "wjI9DBXAY8hR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RANDOM_STATE=233"
      ],
      "metadata": {
        "id": "CQKLdMHVLbKx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check what device we're using\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "torch.set_grad_enabled(True) "
      ],
      "metadata": {
        "id": "-oVz-OIwUZWJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abc4187-572e-42a0-c690-546ee5a70f05"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7f4bb7726b90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading Data and Performing Exploratory Data Analysis \n",
        "\n",
        "The process is similar to the pre-processing done in Homework 3 as we are trying to solve the same problem with a different model.\n",
        "\n",
        "Exploratory Data Analysis - Additional comments on dataset, cleaning, and visualization have been provided where needed."
      ],
      "metadata": {
        "id": "ghEEe2IGijzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#quick mv command for misplaced files\n",
        "#mv  *.txt Athlete_D"
      ],
      "metadata": {
        "id": "RZhwOYyGyjEO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join"
      ],
      "metadata": {
        "id": "SZwTswaYzdS5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dir = \"Athlete_D\"\n",
        "ath_D_array = [f for f in listdir(test_dir) if isfile(join(test_dir, f))]\n",
        "print(ath_D_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHBaJUyGzhcx",
        "outputId": "62e17a9d-b618-4502-ce85-7f250d05e815"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['D_shoot4.txt', 'D_shoot5.txt', 'D_dribble1.txt', 'D_pass2.txt', 'D_pickup5.txt', 'D_pass5.txt', 'D_pass6.txt', 'D_pickup2.txt', 'D_hold2.txt', 'D_dribble3.txt', 'D_pickup3.txt', 'D_hold1.txt', 'D_shoot2.txt', 'D_pass3.txt', 'D_shoot1.txt', 'D_pickup4.txt', 'D_pass4.txt', 'D_dribble2.txt', 'D_pass1.txt', 'D_pickup1.txt', 'D_shoot3.txt', 'D_hold3.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Athletes were categorized by initial, so we sort them accordingly \n",
        "#into folders before starting processing\n",
        "#File names are marked as INITIAL_ACTION(NUMBER).\n",
        "#We will use the ACTION \n",
        "athlete_folders = [\"Athlete_D\",\"Athlete_Jc\", \"Athlete_L\", \"Athlete_X\"]\n",
        "actions = [\"dribble\",\"hold\",\"pass\",\"pickup\",\"shoot\"] #label will correspond to index number"
      ],
      "metadata": {
        "id": "dso52Ui3z4jM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test with reading one file\n",
        "newcol= \"Action\"\n",
        "df = pd.read_table(\"Athlete_D/D_dribble1.txt\", delimiter=\",\", skiprows=3)\n",
        "df[newcol]=0"
      ],
      "metadata": {
        "id": "kg8U4NKIi6gk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "Q9rK-SGvsDt5",
        "outputId": "ad55229d-20cb-4d3f-ee74-e827083d31ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0    0.000000   3.428497   9.112331  -2.047042   9.948847    101.873802   \n",
              "1    0.009703   3.447650   9.285912  -2.331953  10.176072    103.247643   \n",
              "2    0.019734   3.506308   9.212888  -2.244564  10.109875    102.827530   \n",
              "3    0.029704   3.703830   8.972271  -1.990779   9.908744    101.590256   \n",
              "4    0.039805   3.902549   8.799889  -1.545457   9.749685     99.120628   \n",
              "..        ...        ...        ...        ...        ...           ...   \n",
              "984  9.879907   3.989937   8.725668  -0.760159   9.624694     94.529945   \n",
              "985  9.889970   4.096479   8.585608  -0.766145   9.543624     94.604553   \n",
              "986  9.900604   4.034230   8.754398  -0.822408   9.674236     94.876610   \n",
              "987  9.910431   3.951630   9.159019  -1.513135  10.089231     98.625496   \n",
              "988  9.919714   3.681085   9.283517  -2.084153  10.201851    101.788033   \n",
              "\n",
              "      Phi (deg)  Action  \n",
              "0     69.381287       0  \n",
              "1     69.631172       0  \n",
              "2     69.163811       0  \n",
              "3     67.568748       0  \n",
              "4     66.083809       0  \n",
              "..          ...     ...  \n",
              "984   65.427071       0  \n",
              "985   64.492638       0  \n",
              "986   65.258652       0  \n",
              "987   66.662369       0  \n",
              "988   68.370766       0  \n",
              "\n",
              "[989 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d53df5f-36f9-4c0a-92e6-ccb7a24949bb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.428497</td>\n",
              "      <td>9.112331</td>\n",
              "      <td>-2.047042</td>\n",
              "      <td>9.948847</td>\n",
              "      <td>101.873802</td>\n",
              "      <td>69.381287</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009703</td>\n",
              "      <td>3.447650</td>\n",
              "      <td>9.285912</td>\n",
              "      <td>-2.331953</td>\n",
              "      <td>10.176072</td>\n",
              "      <td>103.247643</td>\n",
              "      <td>69.631172</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.019734</td>\n",
              "      <td>3.506308</td>\n",
              "      <td>9.212888</td>\n",
              "      <td>-2.244564</td>\n",
              "      <td>10.109875</td>\n",
              "      <td>102.827530</td>\n",
              "      <td>69.163811</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.029704</td>\n",
              "      <td>3.703830</td>\n",
              "      <td>8.972271</td>\n",
              "      <td>-1.990779</td>\n",
              "      <td>9.908744</td>\n",
              "      <td>101.590256</td>\n",
              "      <td>67.568748</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039805</td>\n",
              "      <td>3.902549</td>\n",
              "      <td>8.799889</td>\n",
              "      <td>-1.545457</td>\n",
              "      <td>9.749685</td>\n",
              "      <td>99.120628</td>\n",
              "      <td>66.083809</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>9.879907</td>\n",
              "      <td>3.989937</td>\n",
              "      <td>8.725668</td>\n",
              "      <td>-0.760159</td>\n",
              "      <td>9.624694</td>\n",
              "      <td>94.529945</td>\n",
              "      <td>65.427071</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985</th>\n",
              "      <td>9.889970</td>\n",
              "      <td>4.096479</td>\n",
              "      <td>8.585608</td>\n",
              "      <td>-0.766145</td>\n",
              "      <td>9.543624</td>\n",
              "      <td>94.604553</td>\n",
              "      <td>64.492638</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>9.900604</td>\n",
              "      <td>4.034230</td>\n",
              "      <td>8.754398</td>\n",
              "      <td>-0.822408</td>\n",
              "      <td>9.674236</td>\n",
              "      <td>94.876610</td>\n",
              "      <td>65.258652</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>987</th>\n",
              "      <td>9.910431</td>\n",
              "      <td>3.951630</td>\n",
              "      <td>9.159019</td>\n",
              "      <td>-1.513135</td>\n",
              "      <td>10.089231</td>\n",
              "      <td>98.625496</td>\n",
              "      <td>66.662369</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>988</th>\n",
              "      <td>9.919714</td>\n",
              "      <td>3.681085</td>\n",
              "      <td>9.283517</td>\n",
              "      <td>-2.084153</td>\n",
              "      <td>10.201851</td>\n",
              "      <td>101.788033</td>\n",
              "      <td>68.370766</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>989 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d53df5f-36f9-4c0a-92e6-ccb7a24949bb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d53df5f-36f9-4c0a-92e6-ccb7a24949bb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d53df5f-36f9-4c0a-92e6-ccb7a24949bb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfcols = [\"Time (s)\", \"X (m/s2)\", \"Y (m/s2)\", \"Z (m/s2)\", \"R (m/s2)\", \"Theta (deg)\", \"Phi (deg)\", \"Action\"]\n",
        "all_df = pd.DataFrame(columns = dfcols)"
      ],
      "metadata": {
        "id": "K_bnfhuJ7MOs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "hMTx82qV7QQo",
        "outputId": "1224d86a-8f80-4645-d828-1ab78f8ab4b4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Time (s), X (m/s2), Y (m/s2), Z (m/s2), R (m/s2), Theta (deg), Phi (deg), Action]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2200b4ed-862f-47ab-8bdb-9bdc268d5cb3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2200b4ed-862f-47ab-8bdb-9bdc268d5cb3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2200b4ed-862f-47ab-8bdb-9bdc268d5cb3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2200b4ed-862f-47ab-8bdb-9bdc268d5cb3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myframes = []\n",
        "for foldername in athlete_folders:\n",
        "  textfiles = [f for f in listdir(foldername) if isfile(join(foldername, f))]\n",
        "  for textfile in textfiles:\n",
        "    fullpath = foldername + \"/\" + textfile\n",
        "    df_temp = pd.read_table(fullpath, delimiter=\",\", skiprows=3)\n",
        "    if \"dribble\" in textfile:\n",
        "        df_temp[\"Action\"] = 0\n",
        "    elif \"hold\" in textfile:\n",
        "        df_temp[\"Action\"] = 1\n",
        "    elif \"pass\" in textfile:\n",
        "        df_temp[\"Action\"] = 2\n",
        "    elif \"pickup\" in textfile:\n",
        "        df_temp[\"Action\"] = 3\n",
        "    elif \"shoot\" in textfile:\n",
        "        df_temp[\"Action\"] = 4\n",
        "    else:\n",
        "        df_temp[\"Action\"] = 5 #this label represents INVALID data.\n",
        "    myframes.append(df_temp)"
      ],
      "metadata": {
        "id": "2ENfG2b_4BO2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(myframes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxrsckqi7y74",
        "outputId": "dfee37b4-8f6b-48f8-a19d-660a328b97b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "79"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.concat(myframes)"
      ],
      "metadata": {
        "id": "28YwTEJq7Je0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#52913 rows × 8 columns\n",
        "all_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "P1F_h7Iu9jF6",
        "outputId": "404ffe1c-0d91-4a5d-db46-6acdbb0e6ecc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0    0.000000   8.186973   4.508282  -2.455254   9.663301    104.719093   \n",
              "1    0.016081   8.638280   4.398149  -1.725022   9.845776    100.090546   \n",
              "2    0.025817   8.955511   4.375403  -0.958878  10.013230     95.495125   \n",
              "3    0.035936   9.194932   4.273650  -0.556652  10.154838     93.142326   \n",
              "4    0.045710   9.251195   4.232949  -0.605733  10.191632     93.407349   \n",
              "..        ...        ...        ...        ...        ...           ...   \n",
              "574  5.780185   0.017450   0.997584   0.107751   1.003538     83.836189   \n",
              "575  5.789986   0.026846   0.994167   0.112144   1.000832     83.566437   \n",
              "576  5.800642   0.034412   0.992093   0.130205   1.001192     82.527542   \n",
              "577  5.810363   0.058452   0.961830   0.160468   0.976874     80.545372   \n",
              "578  5.820461   0.046005   1.015156   0.055645   1.017720     86.865723   \n",
              "\n",
              "      Phi (deg)  Action  \n",
              "0     28.840052       4  \n",
              "1     26.982752       4  \n",
              "2     26.038795       4  \n",
              "3     24.928215       4  \n",
              "4     24.586794       4  \n",
              "..          ...     ...  \n",
              "574   88.997864       3  \n",
              "575   88.453171       3  \n",
              "576   88.013412       3  \n",
              "577   86.522331       3  \n",
              "578   87.405251       3  \n",
              "\n",
              "[52913 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aabb0df2-35e5-4c13-a8a3-a723eb4037a8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.186973</td>\n",
              "      <td>4.508282</td>\n",
              "      <td>-2.455254</td>\n",
              "      <td>9.663301</td>\n",
              "      <td>104.719093</td>\n",
              "      <td>28.840052</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.016081</td>\n",
              "      <td>8.638280</td>\n",
              "      <td>4.398149</td>\n",
              "      <td>-1.725022</td>\n",
              "      <td>9.845776</td>\n",
              "      <td>100.090546</td>\n",
              "      <td>26.982752</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.025817</td>\n",
              "      <td>8.955511</td>\n",
              "      <td>4.375403</td>\n",
              "      <td>-0.958878</td>\n",
              "      <td>10.013230</td>\n",
              "      <td>95.495125</td>\n",
              "      <td>26.038795</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.035936</td>\n",
              "      <td>9.194932</td>\n",
              "      <td>4.273650</td>\n",
              "      <td>-0.556652</td>\n",
              "      <td>10.154838</td>\n",
              "      <td>93.142326</td>\n",
              "      <td>24.928215</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.045710</td>\n",
              "      <td>9.251195</td>\n",
              "      <td>4.232949</td>\n",
              "      <td>-0.605733</td>\n",
              "      <td>10.191632</td>\n",
              "      <td>93.407349</td>\n",
              "      <td>24.586794</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>5.780185</td>\n",
              "      <td>0.017450</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.107751</td>\n",
              "      <td>1.003538</td>\n",
              "      <td>83.836189</td>\n",
              "      <td>88.997864</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>5.789986</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.994167</td>\n",
              "      <td>0.112144</td>\n",
              "      <td>1.000832</td>\n",
              "      <td>83.566437</td>\n",
              "      <td>88.453171</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>5.800642</td>\n",
              "      <td>0.034412</td>\n",
              "      <td>0.992093</td>\n",
              "      <td>0.130205</td>\n",
              "      <td>1.001192</td>\n",
              "      <td>82.527542</td>\n",
              "      <td>88.013412</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>5.810363</td>\n",
              "      <td>0.058452</td>\n",
              "      <td>0.961830</td>\n",
              "      <td>0.160468</td>\n",
              "      <td>0.976874</td>\n",
              "      <td>80.545372</td>\n",
              "      <td>86.522331</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>5.820461</td>\n",
              "      <td>0.046005</td>\n",
              "      <td>1.015156</td>\n",
              "      <td>0.055645</td>\n",
              "      <td>1.017720</td>\n",
              "      <td>86.865723</td>\n",
              "      <td>87.405251</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52913 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aabb0df2-35e5-4c13-a8a3-a723eb4037a8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aabb0df2-35e5-4c13-a8a3-a723eb4037a8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aabb0df2-35e5-4c13-a8a3-a723eb4037a8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "invalid_data = df.loc[df['Action'] == 5]"
      ],
      "metadata": {
        "id": "3bpiZaKh9r05"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all of our data is valid actions!\n",
        "#we have 52913 examples to work with\n",
        "invalid_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "v3zC47C197kr",
        "outputId": "2de67f80-e876-4db2-9188-3883ea3f2771"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Time (s),  X (m/s2),  Y (m/s2),  Z (m/s2),  R (m/s2),  Theta (deg),  Phi (deg), Action]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4018535c-f94b-4e7c-84a4-1a194c635e4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4018535c-f94b-4e7c-84a4-1a194c635e4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4018535c-f94b-4e7c-84a4-1a194c635e4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4018535c-f94b-4e7c-84a4-1a194c635e4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test= all_df.loc[all_df['Action'] == 3]"
      ],
      "metadata": {
        "id": "3ZZBbNVM_z7u"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "CZXAx0_UAIp0",
        "outputId": "d36f7565-1780-4995-9a02-95880d5d175d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0    0.000000   1.897405   6.508637   7.580042  10.169540     41.809349   \n",
              "1    0.009813   1.783680   6.707356   7.337031  10.099612     43.409012   \n",
              "2    0.019684   1.868674   7.147889   7.380127  10.442726     45.030994   \n",
              "3    0.029636   1.713051   6.873753   7.319075  10.185866     44.064941   \n",
              "4    0.039645   1.448492   6.623559   7.020997   9.760330     43.999977   \n",
              "..        ...        ...        ...        ...        ...           ...   \n",
              "574  5.780185   0.017450   0.997584   0.107751   1.003538     83.836189   \n",
              "575  5.789986   0.026846   0.994167   0.112144   1.000832     83.566437   \n",
              "576  5.800642   0.034412   0.992093   0.130205   1.001192     82.527542   \n",
              "577  5.810363   0.058452   0.961830   0.160468   0.976874     80.545372   \n",
              "578  5.820461   0.046005   1.015156   0.055645   1.017720     86.865723   \n",
              "\n",
              "      Phi (deg)  Action  \n",
              "0     73.747482       3  \n",
              "1     75.108047       3  \n",
              "2     75.349052       3  \n",
              "3     76.006027       3  \n",
              "4     77.664307       3  \n",
              "..          ...     ...  \n",
              "574   88.997864       3  \n",
              "575   88.453171       3  \n",
              "576   88.013412       3  \n",
              "577   86.522331       3  \n",
              "578   87.405251       3  \n",
              "\n",
              "[15388 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9703345-6670-48cb-adcb-5891b4a166c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.897405</td>\n",
              "      <td>6.508637</td>\n",
              "      <td>7.580042</td>\n",
              "      <td>10.169540</td>\n",
              "      <td>41.809349</td>\n",
              "      <td>73.747482</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.009813</td>\n",
              "      <td>1.783680</td>\n",
              "      <td>6.707356</td>\n",
              "      <td>7.337031</td>\n",
              "      <td>10.099612</td>\n",
              "      <td>43.409012</td>\n",
              "      <td>75.108047</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.019684</td>\n",
              "      <td>1.868674</td>\n",
              "      <td>7.147889</td>\n",
              "      <td>7.380127</td>\n",
              "      <td>10.442726</td>\n",
              "      <td>45.030994</td>\n",
              "      <td>75.349052</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.029636</td>\n",
              "      <td>1.713051</td>\n",
              "      <td>6.873753</td>\n",
              "      <td>7.319075</td>\n",
              "      <td>10.185866</td>\n",
              "      <td>44.064941</td>\n",
              "      <td>76.006027</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.039645</td>\n",
              "      <td>1.448492</td>\n",
              "      <td>6.623559</td>\n",
              "      <td>7.020997</td>\n",
              "      <td>9.760330</td>\n",
              "      <td>43.999977</td>\n",
              "      <td>77.664307</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>574</th>\n",
              "      <td>5.780185</td>\n",
              "      <td>0.017450</td>\n",
              "      <td>0.997584</td>\n",
              "      <td>0.107751</td>\n",
              "      <td>1.003538</td>\n",
              "      <td>83.836189</td>\n",
              "      <td>88.997864</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>575</th>\n",
              "      <td>5.789986</td>\n",
              "      <td>0.026846</td>\n",
              "      <td>0.994167</td>\n",
              "      <td>0.112144</td>\n",
              "      <td>1.000832</td>\n",
              "      <td>83.566437</td>\n",
              "      <td>88.453171</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>5.800642</td>\n",
              "      <td>0.034412</td>\n",
              "      <td>0.992093</td>\n",
              "      <td>0.130205</td>\n",
              "      <td>1.001192</td>\n",
              "      <td>82.527542</td>\n",
              "      <td>88.013412</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>577</th>\n",
              "      <td>5.810363</td>\n",
              "      <td>0.058452</td>\n",
              "      <td>0.961830</td>\n",
              "      <td>0.160468</td>\n",
              "      <td>0.976874</td>\n",
              "      <td>80.545372</td>\n",
              "      <td>86.522331</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>5.820461</td>\n",
              "      <td>0.046005</td>\n",
              "      <td>1.015156</td>\n",
              "      <td>0.055645</td>\n",
              "      <td>1.017720</td>\n",
              "      <td>86.865723</td>\n",
              "      <td>87.405251</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15388 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9703345-6670-48cb-adcb-5891b4a166c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9703345-6670-48cb-adcb-5891b4a166c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9703345-6670-48cb-adcb-5891b4a166c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-veEhtcM_7Nn",
        "outputId": "fb8c69da-4103-4bec-ea7b-b1bc83174962"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15388"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#is data balanced?\n",
        "numdata = []\n",
        "\n",
        "for i in range (0,5):\n",
        "  numdata.append(len(all_df.loc[all_df['Action'] == i]))"
      ],
      "metadata": {
        "id": "2Vstuw9Y-Dk5"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numdata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZF-V61pAbsh",
        "outputId": "03100c8a-e580-4326-bde3-1367f6dea5fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12823, 6369, 11363, 15388, 6970]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nd = pd.DataFrame(numdata, columns=[''])\n",
        "ax = df_nd.plot(kind='bar', title = \"action distribution\")\n",
        "ax.set_xlabel(\"action label\")\n",
        "ax.set_ylabel(\"frequency\")\n",
        "ax.get_legend().remove()\n",
        "plt.show()\n",
        "#We seem to have less data on the \"hold\" and \"shoot\" actions."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "El5SgFhNA7Ll",
        "outputId": "9925595f-2ef5-493b-8347-9f97bb2121a9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Even if we only took 6369 examples from each dataset, \n",
        "#we would still be left with about 30,000 examples and plenty of data\n",
        "#for train/val/test split\n",
        "#so let's do that via random selection and rejoin the dataset.\n",
        "balanced_combiner = []\n",
        "for i in range (0,5):\n",
        "  chunk_df = all_df.loc[all_df['Action'] == i]\n",
        "  balanced_temp = chunk_df.sample(n=6369, random_state=RANDOM_STATE)\n",
        "  balanced_combiner.append(balanced_temp)\n",
        "balanced_all = pd.concat(balanced_combiner)\n",
        "balanced_all = balanced_all.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "d7lUeD0-DhBH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "-C2079FKEPB4",
        "outputId": "ba41c73f-20ae-420d-b0b0-21bbe6856b79"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0      9.286569   7.256825   8.359355   6.147113  12.662043     60.956364   \n",
              "1      6.639866   6.519411   3.245340  -0.055067   7.282718     90.433235   \n",
              "2      1.688493   2.024297   9.538500   1.538275   9.871527     81.035095   \n",
              "3      4.938691   2.151190   8.353370   1.295263   8.722620     81.460297   \n",
              "4      0.860075   1.766921   9.403227   2.286463   9.837205     76.559814   \n",
              "...         ...        ...        ...        ...        ...           ...   \n",
              "31840  0.330058   5.899313   8.258799   0.590171  10.166512     86.672081   \n",
              "31841  2.780179   4.721366   8.475474  -0.435745   9.711582     92.571640   \n",
              "31842  4.340031   0.363889   0.911066   0.253575   1.013290     75.507713   \n",
              "31843  3.950385   2.482787   9.063251   0.579397   9.415011     86.471809   \n",
              "31844  2.609959   2.669535   7.807492   0.009577   8.251268     89.933502   \n",
              "\n",
              "        Phi (deg)  Action  \n",
              "0       49.038479       0  \n",
              "1       26.463963       0  \n",
              "2       78.018242       0  \n",
              "3       75.558762       0  \n",
              "4       79.357887       0  \n",
              "...           ...     ...  \n",
              "31840   54.461536       4  \n",
              "31841   60.879475       4  \n",
              "31842   68.227707       4  \n",
              "31843   74.680229       4  \n",
              "31844   71.123436       4  \n",
              "\n",
              "[31845 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-629b78cf-f52b-4b3c-ae10-05e1a232b581\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.286569</td>\n",
              "      <td>7.256825</td>\n",
              "      <td>8.359355</td>\n",
              "      <td>6.147113</td>\n",
              "      <td>12.662043</td>\n",
              "      <td>60.956364</td>\n",
              "      <td>49.038479</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.639866</td>\n",
              "      <td>6.519411</td>\n",
              "      <td>3.245340</td>\n",
              "      <td>-0.055067</td>\n",
              "      <td>7.282718</td>\n",
              "      <td>90.433235</td>\n",
              "      <td>26.463963</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.688493</td>\n",
              "      <td>2.024297</td>\n",
              "      <td>9.538500</td>\n",
              "      <td>1.538275</td>\n",
              "      <td>9.871527</td>\n",
              "      <td>81.035095</td>\n",
              "      <td>78.018242</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.938691</td>\n",
              "      <td>2.151190</td>\n",
              "      <td>8.353370</td>\n",
              "      <td>1.295263</td>\n",
              "      <td>8.722620</td>\n",
              "      <td>81.460297</td>\n",
              "      <td>75.558762</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.860075</td>\n",
              "      <td>1.766921</td>\n",
              "      <td>9.403227</td>\n",
              "      <td>2.286463</td>\n",
              "      <td>9.837205</td>\n",
              "      <td>76.559814</td>\n",
              "      <td>79.357887</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31840</th>\n",
              "      <td>0.330058</td>\n",
              "      <td>5.899313</td>\n",
              "      <td>8.258799</td>\n",
              "      <td>0.590171</td>\n",
              "      <td>10.166512</td>\n",
              "      <td>86.672081</td>\n",
              "      <td>54.461536</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31841</th>\n",
              "      <td>2.780179</td>\n",
              "      <td>4.721366</td>\n",
              "      <td>8.475474</td>\n",
              "      <td>-0.435745</td>\n",
              "      <td>9.711582</td>\n",
              "      <td>92.571640</td>\n",
              "      <td>60.879475</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31842</th>\n",
              "      <td>4.340031</td>\n",
              "      <td>0.363889</td>\n",
              "      <td>0.911066</td>\n",
              "      <td>0.253575</td>\n",
              "      <td>1.013290</td>\n",
              "      <td>75.507713</td>\n",
              "      <td>68.227707</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31843</th>\n",
              "      <td>3.950385</td>\n",
              "      <td>2.482787</td>\n",
              "      <td>9.063251</td>\n",
              "      <td>0.579397</td>\n",
              "      <td>9.415011</td>\n",
              "      <td>86.471809</td>\n",
              "      <td>74.680229</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31844</th>\n",
              "      <td>2.609959</td>\n",
              "      <td>2.669535</td>\n",
              "      <td>7.807492</td>\n",
              "      <td>0.009577</td>\n",
              "      <td>8.251268</td>\n",
              "      <td>89.933502</td>\n",
              "      <td>71.123436</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31845 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-629b78cf-f52b-4b3c-ae10-05e1a232b581')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-629b78cf-f52b-4b3c-ae10-05e1a232b581 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-629b78cf-f52b-4b3c-ae10-05e1a232b581');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Looks balanced!\n",
        "numdatanew = []\n",
        "for i in range (0,5):\n",
        "  numdatanew.append(len(balanced_all.loc[balanced_all['Action'] == i]))\n",
        "print(numdatanew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwR5eU9yEUwK",
        "outputId": "82aabad2-5274-4556-9895-c7a2e69d64c6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6369, 6369, 6369, 6369, 6369]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_nd = pd.DataFrame(numdatanew, columns=[''])\n",
        "ax = df_nd.plot(kind='bar', title = \"action distribution\")\n",
        "ax.set_xlabel(\"action label\")\n",
        "ax.set_ylabel(\"frequency\")\n",
        "ax.get_legend().remove()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "2n4dbDcnEk57",
        "outputId": "99b16525-a5cd-42aa-db33-d5cdb29c5b95"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary of all stats\n",
        "#Some of the stats - especailly those involve degrees\n",
        "#vary wildly, as indicated by std.\n",
        "#We will normalize these following a train/val/test split.\n",
        "balanced_all.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "EuCk4SA4GDPn",
        "outputId": "88dc7ef8-4afe-40f3-eacc-7d823547eb00"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Time (s)      X (m/s2)      Y (m/s2)      Z (m/s2)      R (m/s2)  \\\n",
              "count  31845.000000  31845.000000  31845.000000  31845.000000  31845.000000   \n",
              "mean       3.683098      3.391771      6.546430      1.006166      8.645987   \n",
              "std        2.932378      3.980442      4.079775      2.661092      4.493152   \n",
              "min        0.000000    -39.195477    -14.277822    -33.500866      0.077691   \n",
              "25%        1.528668      0.535340      4.279635      0.064919      8.797799   \n",
              "50%        3.060462      3.308787      7.999028      0.770933      9.833359   \n",
              "75%        5.010264      5.279215      9.096769      1.896208      9.997210   \n",
              "max       20.650665     38.476017     39.221813     28.358122     54.321270   \n",
              "\n",
              "        Theta (deg)     Phi (deg)        Action  \n",
              "count  31845.000000  31845.000000  31845.000000  \n",
              "mean      81.229455     75.411486      2.000000  \n",
              "std       14.820114     51.186228      1.414236  \n",
              "min       12.856148      0.005464      0.000000  \n",
              "25%       75.831467     57.243790      1.000000  \n",
              "50%       80.924576     68.288162      2.000000  \n",
              "75%       88.917969     77.541512      3.000000  \n",
              "max      164.085129    359.945709      4.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fba42a92-82a3-4565-b086-a2700300639e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "      <td>31845.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.683098</td>\n",
              "      <td>3.391771</td>\n",
              "      <td>6.546430</td>\n",
              "      <td>1.006166</td>\n",
              "      <td>8.645987</td>\n",
              "      <td>81.229455</td>\n",
              "      <td>75.411486</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.932378</td>\n",
              "      <td>3.980442</td>\n",
              "      <td>4.079775</td>\n",
              "      <td>2.661092</td>\n",
              "      <td>4.493152</td>\n",
              "      <td>14.820114</td>\n",
              "      <td>51.186228</td>\n",
              "      <td>1.414236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-39.195477</td>\n",
              "      <td>-14.277822</td>\n",
              "      <td>-33.500866</td>\n",
              "      <td>0.077691</td>\n",
              "      <td>12.856148</td>\n",
              "      <td>0.005464</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.528668</td>\n",
              "      <td>0.535340</td>\n",
              "      <td>4.279635</td>\n",
              "      <td>0.064919</td>\n",
              "      <td>8.797799</td>\n",
              "      <td>75.831467</td>\n",
              "      <td>57.243790</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.060462</td>\n",
              "      <td>3.308787</td>\n",
              "      <td>7.999028</td>\n",
              "      <td>0.770933</td>\n",
              "      <td>9.833359</td>\n",
              "      <td>80.924576</td>\n",
              "      <td>68.288162</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.010264</td>\n",
              "      <td>5.279215</td>\n",
              "      <td>9.096769</td>\n",
              "      <td>1.896208</td>\n",
              "      <td>9.997210</td>\n",
              "      <td>88.917969</td>\n",
              "      <td>77.541512</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>20.650665</td>\n",
              "      <td>38.476017</td>\n",
              "      <td>39.221813</td>\n",
              "      <td>28.358122</td>\n",
              "      <td>54.321270</td>\n",
              "      <td>164.085129</td>\n",
              "      <td>359.945709</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fba42a92-82a3-4565-b086-a2700300639e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fba42a92-82a3-4565-b086-a2700300639e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fba42a92-82a3-4565-b086-a2700300639e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at data this way helps us get a better understanding of what the parameters reference as well. For example, \"Time = 0\" would be the representation of an athlete's velocty and angular momentum when starting an action. Actions last up to 20 seconds, meaning that an action's other features can vary depending on the time the action is recorded (for example, if an athlete jumped during an action, their vertical velocity would be positive at one point and negative at another.) "
      ],
      "metadata": {
        "id": "9aPT8VDbIXJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_all.loc[balanced_all['Time (s)'] == 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LKgwhHNfHgOT",
        "outputId": "163c3b1a-4173-445b-cef8-f965c2c155c5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "478         0.0   0.100063   0.818446  -0.051008   0.826116     93.539940   \n",
              "584         0.0   3.479972   9.069236  -2.246958   9.970460    103.024139   \n",
              "2345        0.0   2.612074   9.417592   0.434548   9.782781     87.454102   \n",
              "5426        0.0   2.408567   9.160215   2.091335   9.699713     77.548805   \n",
              "6341        0.0   3.180697   8.923190   1.921347   9.666009     78.534752   \n",
              "6524        0.0   2.998738   9.139865   1.316811   9.708941     82.205025   \n",
              "7039        0.0   5.863400   7.539341  -0.681150   9.575233     94.079277   \n",
              "7201        0.0   0.391346   0.826256   0.225021   0.941533     76.172829   \n",
              "8266        0.0   0.209889   0.836140   0.076756   0.865491     84.912048   \n",
              "9255        0.0   4.000711   9.130288   1.353921  10.059868     82.265297   \n",
              "9746        0.0   2.960430   8.360553   1.408988   8.980436     80.973267   \n",
              "10153       0.0   5.066131   8.058883  -1.243788   9.599910     97.444305   \n",
              "10519       0.0   2.971204   9.275137   0.166397   9.740837     89.021202   \n",
              "11190       0.0   6.501455   8.044518  -0.800860  10.374226     94.427475   \n",
              "11714       0.0   0.294211   0.880559   0.122395   0.936442     82.489853   \n",
              "12142       0.0   2.920926   9.548077   0.484826   9.996631     87.220123   \n",
              "12676       0.0   3.470395   9.206903   0.305261   9.843977     88.222977   \n",
              "13013       0.0   4.649539   8.690952   0.926556   9.899968     84.629723   \n",
              "14038       0.0   4.277241   8.761581  -1.459266   9.858477     98.512283   \n",
              "14271       0.0   4.047398   8.304289  -3.818752   9.996275    112.458710   \n",
              "15577       0.0   6.669049   6.271611  -2.852691   9.588908    107.307457   \n",
              "16028       0.0   0.132889   0.910334   0.201103   0.941705     77.669403   \n",
              "16143       0.0   4.356250   9.041702   0.721852  10.062325     85.886177   \n",
              "16317       0.0   8.249222   6.084864   1.988384  10.441690     79.022270   \n",
              "16526       0.0   7.316680   5.342661  -1.094150   9.125514     96.886337   \n",
              "16854       0.0   0.359740   0.904354   0.357300   1.036790     69.841316   \n",
              "17143       0.0   8.256405   5.963956  -3.403358  10.738708    108.477020   \n",
              "18954       0.0   3.957615   8.396465   2.477999   9.607489     75.053108   \n",
              "19266       0.0   1.349133   3.952827   8.995016   9.917425     24.907204   \n",
              "19754       0.0   1.906982   8.396465   4.596867   9.760553     61.903126   \n",
              "20109       0.0  -0.019647   1.045419  -0.098111   1.050197     95.360481   \n",
              "20133       0.0   0.374693   5.898116   7.805098   9.790185     37.132942   \n",
              "20483       0.0   0.733823   5.342661   7.910442   9.573799     34.283607   \n",
              "20888       0.0  -0.180480   1.044077  -0.098477   1.064128     95.309898   \n",
              "24867       0.0   0.423774   4.982334   7.442376   8.966169     33.896042   \n",
              "25328       0.0   3.220201   6.949171   4.565742   8.916651     59.199738   \n",
              "25537       0.0   7.295133   6.556521  -1.624466   9.942123     99.403847   \n",
              "26168       0.0   6.373365   6.652289  -2.111686   9.451558    102.910103   \n",
              "27194       0.0   0.001197   9.810242  -0.128090   9.811078     90.748055   \n",
              "27290       0.0   1.769315   9.482236  -0.778116   9.677228     94.611954   \n",
              "27293       0.0   0.203544   0.967077   0.145092   0.998859     81.647797   \n",
              "27323       0.0   4.927267   8.297106  -1.447295   9.757796     98.529694   \n",
              "27366       0.0   2.158373   8.790312   1.083376   9.116022     83.174660   \n",
              "27754       0.0   2.220622   8.841787  -0.401029   9.125196     92.518814   \n",
              "27858       0.0  -0.052838   0.856031  -0.056987   0.859551     93.801437   \n",
              "29284       0.0   1.904588   9.714474   1.030704   9.952929     84.055916   \n",
              "29435       0.0   0.118612   0.885806   0.216357   0.919528     76.391212   \n",
              "29655       0.0   2.998738   8.510190  -0.070629   9.023344     90.448479   \n",
              "30016       0.0   0.308852   8.471883   0.627281   8.500687     85.768196   \n",
              "30096       0.0   2.110489   9.163807  -0.760159   9.434371     94.621521   \n",
              "30180       0.0   6.846220   6.313510  -2.704251   9.697634    106.191986   \n",
              "30761       0.0   8.186973   4.508282  -2.455254   9.663301    104.719093   \n",
              "31224       0.0   0.708684   9.187749   0.842759   9.253497     84.774567   \n",
              "\n",
              "        Phi (deg)  Action  \n",
              "478     83.029594       0  \n",
              "584     69.007607       0  \n",
              "2345    74.498055       0  \n",
              "5426    75.268234       0  \n",
              "6341    70.381241       0  \n",
              "6524    71.835632       1  \n",
              "7039    52.127537       1  \n",
              "7201    64.656006       1  \n",
              "8266    75.908676       1  \n",
              "9255    66.337921       1  \n",
              "9746    70.501198       1  \n",
              "10153   57.844917       1  \n",
              "10519   72.237617       1  \n",
              "11190   51.055393       1  \n",
              "11714   71.524567       1  \n",
              "12142   72.990196       1  \n",
              "12676   69.346863       1  \n",
              "13013   61.853836       2  \n",
              "14038   63.979229       2  \n",
              "14271   64.016022       2  \n",
              "15577   43.240868       2  \n",
              "16028   81.694710       2  \n",
              "16143   64.275452       2  \n",
              "16317   36.413555       2  \n",
              "16526   36.137024       2  \n",
              "16854   68.307976       2  \n",
              "17143   35.842201       2  \n",
              "18954   64.763481       2  \n",
              "19266   71.154800       3  \n",
              "19754   77.204208       3  \n",
              "20109   91.076637       3  \n",
              "20133   86.365028       3  \n",
              "20483   82.179268       3  \n",
              "20888   99.807297       3  \n",
              "24867   85.138397       3  \n",
              "25328   65.137291       3  \n",
              "25537   41.947708       4  \n",
              "26168   46.226715       4  \n",
              "27194   89.993011       4  \n",
              "27290   79.430580       4  \n",
              "27293   78.114258       4  \n",
              "27323   59.295887       4  \n",
              "27366   76.204514       4  \n",
              "27754   75.901718       4  \n",
              "27858   93.532097       4  \n",
              "29284   78.907478       4  \n",
              "29435   82.373306       4  \n",
              "29655   70.589058       4  \n",
              "30016   87.912140       4  \n",
              "30096   77.030533       4  \n",
              "30180   42.681915       4  \n",
              "30761   28.840052       4  \n",
              "31224   85.589310       4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-49a74f49-d6ae-4be5-a07a-33c41e922388\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.100063</td>\n",
              "      <td>0.818446</td>\n",
              "      <td>-0.051008</td>\n",
              "      <td>0.826116</td>\n",
              "      <td>93.539940</td>\n",
              "      <td>83.029594</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>584</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.479972</td>\n",
              "      <td>9.069236</td>\n",
              "      <td>-2.246958</td>\n",
              "      <td>9.970460</td>\n",
              "      <td>103.024139</td>\n",
              "      <td>69.007607</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2345</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.612074</td>\n",
              "      <td>9.417592</td>\n",
              "      <td>0.434548</td>\n",
              "      <td>9.782781</td>\n",
              "      <td>87.454102</td>\n",
              "      <td>74.498055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5426</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.408567</td>\n",
              "      <td>9.160215</td>\n",
              "      <td>2.091335</td>\n",
              "      <td>9.699713</td>\n",
              "      <td>77.548805</td>\n",
              "      <td>75.268234</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6341</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.180697</td>\n",
              "      <td>8.923190</td>\n",
              "      <td>1.921347</td>\n",
              "      <td>9.666009</td>\n",
              "      <td>78.534752</td>\n",
              "      <td>70.381241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6524</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.998738</td>\n",
              "      <td>9.139865</td>\n",
              "      <td>1.316811</td>\n",
              "      <td>9.708941</td>\n",
              "      <td>82.205025</td>\n",
              "      <td>71.835632</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7039</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.863400</td>\n",
              "      <td>7.539341</td>\n",
              "      <td>-0.681150</td>\n",
              "      <td>9.575233</td>\n",
              "      <td>94.079277</td>\n",
              "      <td>52.127537</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7201</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.391346</td>\n",
              "      <td>0.826256</td>\n",
              "      <td>0.225021</td>\n",
              "      <td>0.941533</td>\n",
              "      <td>76.172829</td>\n",
              "      <td>64.656006</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8266</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.209889</td>\n",
              "      <td>0.836140</td>\n",
              "      <td>0.076756</td>\n",
              "      <td>0.865491</td>\n",
              "      <td>84.912048</td>\n",
              "      <td>75.908676</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9255</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.000711</td>\n",
              "      <td>9.130288</td>\n",
              "      <td>1.353921</td>\n",
              "      <td>10.059868</td>\n",
              "      <td>82.265297</td>\n",
              "      <td>66.337921</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9746</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.960430</td>\n",
              "      <td>8.360553</td>\n",
              "      <td>1.408988</td>\n",
              "      <td>8.980436</td>\n",
              "      <td>80.973267</td>\n",
              "      <td>70.501198</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10153</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.066131</td>\n",
              "      <td>8.058883</td>\n",
              "      <td>-1.243788</td>\n",
              "      <td>9.599910</td>\n",
              "      <td>97.444305</td>\n",
              "      <td>57.844917</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10519</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.971204</td>\n",
              "      <td>9.275137</td>\n",
              "      <td>0.166397</td>\n",
              "      <td>9.740837</td>\n",
              "      <td>89.021202</td>\n",
              "      <td>72.237617</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11190</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.501455</td>\n",
              "      <td>8.044518</td>\n",
              "      <td>-0.800860</td>\n",
              "      <td>10.374226</td>\n",
              "      <td>94.427475</td>\n",
              "      <td>51.055393</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11714</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.294211</td>\n",
              "      <td>0.880559</td>\n",
              "      <td>0.122395</td>\n",
              "      <td>0.936442</td>\n",
              "      <td>82.489853</td>\n",
              "      <td>71.524567</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12142</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.920926</td>\n",
              "      <td>9.548077</td>\n",
              "      <td>0.484826</td>\n",
              "      <td>9.996631</td>\n",
              "      <td>87.220123</td>\n",
              "      <td>72.990196</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12676</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.470395</td>\n",
              "      <td>9.206903</td>\n",
              "      <td>0.305261</td>\n",
              "      <td>9.843977</td>\n",
              "      <td>88.222977</td>\n",
              "      <td>69.346863</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13013</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.649539</td>\n",
              "      <td>8.690952</td>\n",
              "      <td>0.926556</td>\n",
              "      <td>9.899968</td>\n",
              "      <td>84.629723</td>\n",
              "      <td>61.853836</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14038</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.277241</td>\n",
              "      <td>8.761581</td>\n",
              "      <td>-1.459266</td>\n",
              "      <td>9.858477</td>\n",
              "      <td>98.512283</td>\n",
              "      <td>63.979229</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14271</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.047398</td>\n",
              "      <td>8.304289</td>\n",
              "      <td>-3.818752</td>\n",
              "      <td>9.996275</td>\n",
              "      <td>112.458710</td>\n",
              "      <td>64.016022</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15577</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.669049</td>\n",
              "      <td>6.271611</td>\n",
              "      <td>-2.852691</td>\n",
              "      <td>9.588908</td>\n",
              "      <td>107.307457</td>\n",
              "      <td>43.240868</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16028</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.132889</td>\n",
              "      <td>0.910334</td>\n",
              "      <td>0.201103</td>\n",
              "      <td>0.941705</td>\n",
              "      <td>77.669403</td>\n",
              "      <td>81.694710</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16143</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.356250</td>\n",
              "      <td>9.041702</td>\n",
              "      <td>0.721852</td>\n",
              "      <td>10.062325</td>\n",
              "      <td>85.886177</td>\n",
              "      <td>64.275452</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16317</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.249222</td>\n",
              "      <td>6.084864</td>\n",
              "      <td>1.988384</td>\n",
              "      <td>10.441690</td>\n",
              "      <td>79.022270</td>\n",
              "      <td>36.413555</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16526</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7.316680</td>\n",
              "      <td>5.342661</td>\n",
              "      <td>-1.094150</td>\n",
              "      <td>9.125514</td>\n",
              "      <td>96.886337</td>\n",
              "      <td>36.137024</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16854</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.359740</td>\n",
              "      <td>0.904354</td>\n",
              "      <td>0.357300</td>\n",
              "      <td>1.036790</td>\n",
              "      <td>69.841316</td>\n",
              "      <td>68.307976</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17143</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.256405</td>\n",
              "      <td>5.963956</td>\n",
              "      <td>-3.403358</td>\n",
              "      <td>10.738708</td>\n",
              "      <td>108.477020</td>\n",
              "      <td>35.842201</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18954</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.957615</td>\n",
              "      <td>8.396465</td>\n",
              "      <td>2.477999</td>\n",
              "      <td>9.607489</td>\n",
              "      <td>75.053108</td>\n",
              "      <td>64.763481</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19266</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.349133</td>\n",
              "      <td>3.952827</td>\n",
              "      <td>8.995016</td>\n",
              "      <td>9.917425</td>\n",
              "      <td>24.907204</td>\n",
              "      <td>71.154800</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19754</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.906982</td>\n",
              "      <td>8.396465</td>\n",
              "      <td>4.596867</td>\n",
              "      <td>9.760553</td>\n",
              "      <td>61.903126</td>\n",
              "      <td>77.204208</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20109</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.019647</td>\n",
              "      <td>1.045419</td>\n",
              "      <td>-0.098111</td>\n",
              "      <td>1.050197</td>\n",
              "      <td>95.360481</td>\n",
              "      <td>91.076637</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20133</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.374693</td>\n",
              "      <td>5.898116</td>\n",
              "      <td>7.805098</td>\n",
              "      <td>9.790185</td>\n",
              "      <td>37.132942</td>\n",
              "      <td>86.365028</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20483</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.733823</td>\n",
              "      <td>5.342661</td>\n",
              "      <td>7.910442</td>\n",
              "      <td>9.573799</td>\n",
              "      <td>34.283607</td>\n",
              "      <td>82.179268</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20888</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.180480</td>\n",
              "      <td>1.044077</td>\n",
              "      <td>-0.098477</td>\n",
              "      <td>1.064128</td>\n",
              "      <td>95.309898</td>\n",
              "      <td>99.807297</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24867</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.423774</td>\n",
              "      <td>4.982334</td>\n",
              "      <td>7.442376</td>\n",
              "      <td>8.966169</td>\n",
              "      <td>33.896042</td>\n",
              "      <td>85.138397</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25328</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3.220201</td>\n",
              "      <td>6.949171</td>\n",
              "      <td>4.565742</td>\n",
              "      <td>8.916651</td>\n",
              "      <td>59.199738</td>\n",
              "      <td>65.137291</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25537</th>\n",
              "      <td>0.0</td>\n",
              "      <td>7.295133</td>\n",
              "      <td>6.556521</td>\n",
              "      <td>-1.624466</td>\n",
              "      <td>9.942123</td>\n",
              "      <td>99.403847</td>\n",
              "      <td>41.947708</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26168</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.373365</td>\n",
              "      <td>6.652289</td>\n",
              "      <td>-2.111686</td>\n",
              "      <td>9.451558</td>\n",
              "      <td>102.910103</td>\n",
              "      <td>46.226715</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27194</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001197</td>\n",
              "      <td>9.810242</td>\n",
              "      <td>-0.128090</td>\n",
              "      <td>9.811078</td>\n",
              "      <td>90.748055</td>\n",
              "      <td>89.993011</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27290</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.769315</td>\n",
              "      <td>9.482236</td>\n",
              "      <td>-0.778116</td>\n",
              "      <td>9.677228</td>\n",
              "      <td>94.611954</td>\n",
              "      <td>79.430580</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27293</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.203544</td>\n",
              "      <td>0.967077</td>\n",
              "      <td>0.145092</td>\n",
              "      <td>0.998859</td>\n",
              "      <td>81.647797</td>\n",
              "      <td>78.114258</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27323</th>\n",
              "      <td>0.0</td>\n",
              "      <td>4.927267</td>\n",
              "      <td>8.297106</td>\n",
              "      <td>-1.447295</td>\n",
              "      <td>9.757796</td>\n",
              "      <td>98.529694</td>\n",
              "      <td>59.295887</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27366</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.158373</td>\n",
              "      <td>8.790312</td>\n",
              "      <td>1.083376</td>\n",
              "      <td>9.116022</td>\n",
              "      <td>83.174660</td>\n",
              "      <td>76.204514</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27754</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.220622</td>\n",
              "      <td>8.841787</td>\n",
              "      <td>-0.401029</td>\n",
              "      <td>9.125196</td>\n",
              "      <td>92.518814</td>\n",
              "      <td>75.901718</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27858</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.052838</td>\n",
              "      <td>0.856031</td>\n",
              "      <td>-0.056987</td>\n",
              "      <td>0.859551</td>\n",
              "      <td>93.801437</td>\n",
              "      <td>93.532097</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29284</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.904588</td>\n",
              "      <td>9.714474</td>\n",
              "      <td>1.030704</td>\n",
              "      <td>9.952929</td>\n",
              "      <td>84.055916</td>\n",
              "      <td>78.907478</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29435</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118612</td>\n",
              "      <td>0.885806</td>\n",
              "      <td>0.216357</td>\n",
              "      <td>0.919528</td>\n",
              "      <td>76.391212</td>\n",
              "      <td>82.373306</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29655</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.998738</td>\n",
              "      <td>8.510190</td>\n",
              "      <td>-0.070629</td>\n",
              "      <td>9.023344</td>\n",
              "      <td>90.448479</td>\n",
              "      <td>70.589058</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30016</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.308852</td>\n",
              "      <td>8.471883</td>\n",
              "      <td>0.627281</td>\n",
              "      <td>8.500687</td>\n",
              "      <td>85.768196</td>\n",
              "      <td>87.912140</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30096</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.110489</td>\n",
              "      <td>9.163807</td>\n",
              "      <td>-0.760159</td>\n",
              "      <td>9.434371</td>\n",
              "      <td>94.621521</td>\n",
              "      <td>77.030533</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30180</th>\n",
              "      <td>0.0</td>\n",
              "      <td>6.846220</td>\n",
              "      <td>6.313510</td>\n",
              "      <td>-2.704251</td>\n",
              "      <td>9.697634</td>\n",
              "      <td>106.191986</td>\n",
              "      <td>42.681915</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30761</th>\n",
              "      <td>0.0</td>\n",
              "      <td>8.186973</td>\n",
              "      <td>4.508282</td>\n",
              "      <td>-2.455254</td>\n",
              "      <td>9.663301</td>\n",
              "      <td>104.719093</td>\n",
              "      <td>28.840052</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31224</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.708684</td>\n",
              "      <td>9.187749</td>\n",
              "      <td>0.842759</td>\n",
              "      <td>9.253497</td>\n",
              "      <td>84.774567</td>\n",
              "      <td>85.589310</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-49a74f49-d6ae-4be5-a07a-33c41e922388')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-49a74f49-d6ae-4be5-a07a-33c41e922388 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-49a74f49-d6ae-4be5-a07a-33c41e922388');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create Train Dev Test Split, Normalize Data, and Convert to Pytorch Data Loaders"
      ],
      "metadata": {
        "id": "ikonpE3xSrnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train-Dev-Test Split\n",
        "Train-dev-test split."
      ],
      "metadata": {
        "id": "oE_-M5ErLIK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle dataset\n",
        "train, test = train_test_split(balanced_all.sample(frac=1, random_state=RANDOM_STATE), test_size=0.2, random_state=RANDOM_STATE)#shuffle dataset\n",
        "train, val = train_test_split(train.sample(frac=1, random_state=RANDOM_STATE), test_size=0.2, random_state=RANDOM_STATE)"
      ],
      "metadata": {
        "id": "rlrPDWwTLSYo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.reset_index(drop=True)\n",
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "N7-V6C2nMMr6",
        "outputId": "3a388578-967f-442d-df82-646819bb311d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0      3.709576  -0.106897   1.038830   0.128374   1.052176     82.991982   \n",
              "1      1.289881  16.652870  -4.095282  -8.127118  18.977341    115.356796   \n",
              "2      4.119909   6.613982   3.858256  -1.103727   7.736221     98.202377   \n",
              "3      1.320370   1.868674   9.373300   2.287660   9.827720     76.539421   \n",
              "4      2.469975   3.408146   9.175778   1.728614   9.939742     79.984810   \n",
              "...         ...        ...        ...        ...        ...           ...   \n",
              "20375  4.859580   6.151901   7.656657   0.915782   9.864530     84.673225   \n",
              "20376  0.769962   4.322731   8.619126   1.618480   9.777260     80.471672   \n",
              "20377  0.900082  21.413740   0.772130  -9.136273  23.294119    113.092316   \n",
              "20378  3.229861   3.933673   9.661801  -0.606930  10.449524     93.329735   \n",
              "20379  7.160092   4.821922   8.645462   2.560599  10.225048     75.497391   \n",
              "\n",
              "        Phi (deg)  Action  \n",
              "0       95.875137       0  \n",
              "1      346.183960       4  \n",
              "2       30.257084       0  \n",
              "3       78.725250       0  \n",
              "4       69.623566       1  \n",
              "...           ...     ...  \n",
              "20375   51.219135       1  \n",
              "20376   63.364964       4  \n",
              "20377    2.065059       4  \n",
              "20378   67.846962       0  \n",
              "20379   60.849834       0  \n",
              "\n",
              "[20380 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b1eeea6-e87c-4f47-8968-25fb464488da\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.709576</td>\n",
              "      <td>-0.106897</td>\n",
              "      <td>1.038830</td>\n",
              "      <td>0.128374</td>\n",
              "      <td>1.052176</td>\n",
              "      <td>82.991982</td>\n",
              "      <td>95.875137</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.289881</td>\n",
              "      <td>16.652870</td>\n",
              "      <td>-4.095282</td>\n",
              "      <td>-8.127118</td>\n",
              "      <td>18.977341</td>\n",
              "      <td>115.356796</td>\n",
              "      <td>346.183960</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.119909</td>\n",
              "      <td>6.613982</td>\n",
              "      <td>3.858256</td>\n",
              "      <td>-1.103727</td>\n",
              "      <td>7.736221</td>\n",
              "      <td>98.202377</td>\n",
              "      <td>30.257084</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.320370</td>\n",
              "      <td>1.868674</td>\n",
              "      <td>9.373300</td>\n",
              "      <td>2.287660</td>\n",
              "      <td>9.827720</td>\n",
              "      <td>76.539421</td>\n",
              "      <td>78.725250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.469975</td>\n",
              "      <td>3.408146</td>\n",
              "      <td>9.175778</td>\n",
              "      <td>1.728614</td>\n",
              "      <td>9.939742</td>\n",
              "      <td>79.984810</td>\n",
              "      <td>69.623566</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20375</th>\n",
              "      <td>4.859580</td>\n",
              "      <td>6.151901</td>\n",
              "      <td>7.656657</td>\n",
              "      <td>0.915782</td>\n",
              "      <td>9.864530</td>\n",
              "      <td>84.673225</td>\n",
              "      <td>51.219135</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20376</th>\n",
              "      <td>0.769962</td>\n",
              "      <td>4.322731</td>\n",
              "      <td>8.619126</td>\n",
              "      <td>1.618480</td>\n",
              "      <td>9.777260</td>\n",
              "      <td>80.471672</td>\n",
              "      <td>63.364964</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20377</th>\n",
              "      <td>0.900082</td>\n",
              "      <td>21.413740</td>\n",
              "      <td>0.772130</td>\n",
              "      <td>-9.136273</td>\n",
              "      <td>23.294119</td>\n",
              "      <td>113.092316</td>\n",
              "      <td>2.065059</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378</th>\n",
              "      <td>3.229861</td>\n",
              "      <td>3.933673</td>\n",
              "      <td>9.661801</td>\n",
              "      <td>-0.606930</td>\n",
              "      <td>10.449524</td>\n",
              "      <td>93.329735</td>\n",
              "      <td>67.846962</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379</th>\n",
              "      <td>7.160092</td>\n",
              "      <td>4.821922</td>\n",
              "      <td>8.645462</td>\n",
              "      <td>2.560599</td>\n",
              "      <td>10.225048</td>\n",
              "      <td>75.497391</td>\n",
              "      <td>60.849834</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20380 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b1eeea6-e87c-4f47-8968-25fb464488da')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b1eeea6-e87c-4f47-8968-25fb464488da button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b1eeea6-e87c-4f47-8968-25fb464488da');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train.loc[:, train.columns != \"Action\"]\n",
        "train_x=(train_x-train_x.mean())/train_x.std() #normalize\n",
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "7CrMCmaKN4ms",
        "outputId": "002e2280-a138-4bd0-f756-c3cd8dc51f60"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0      0.013578  -0.877431  -1.338175  -0.330052  -1.670880      0.119783   \n",
              "1     -0.807542   3.323024  -2.592138  -3.432612   2.287745      2.309548   \n",
              "2      0.152823   0.807005  -0.649554  -0.793097  -0.194764      1.148900   \n",
              "3     -0.797195  -0.382299   0.697448   0.481446   0.267127     -0.316789   \n",
              "4     -0.407079   0.003535   0.649205   0.271346   0.291866     -0.083678   \n",
              "...         ...        ...        ...        ...        ...           ...   \n",
              "20375  0.403829   0.691195   0.278173  -0.034130   0.275256      0.233534   \n",
              "20376 -0.983975   0.232755   0.513248   0.229956   0.255983     -0.050738   \n",
              "20377 -0.939819   4.516228  -1.403314  -3.811870   3.241070      2.156336   \n",
              "20378 -0.149213   0.135246   0.767912  -0.606392   0.404447      0.819223   \n",
              "20379  1.184504   0.357866   0.519680   0.584021   0.354873     -0.387292   \n",
              "\n",
              "        Phi (deg)  \n",
              "0        0.397985  \n",
              "1        5.273173  \n",
              "2       -0.880038  \n",
              "3        0.063962  \n",
              "4       -0.113309  \n",
              "...           ...  \n",
              "20375   -0.471766  \n",
              "20376   -0.235206  \n",
              "20377   -1.429125  \n",
              "20378   -0.147911  \n",
              "20379   -0.284192  \n",
              "\n",
              "[20380 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01b72ce8-ba68-40fa-9e23-540a72a92f8e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013578</td>\n",
              "      <td>-0.877431</td>\n",
              "      <td>-1.338175</td>\n",
              "      <td>-0.330052</td>\n",
              "      <td>-1.670880</td>\n",
              "      <td>0.119783</td>\n",
              "      <td>0.397985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.807542</td>\n",
              "      <td>3.323024</td>\n",
              "      <td>-2.592138</td>\n",
              "      <td>-3.432612</td>\n",
              "      <td>2.287745</td>\n",
              "      <td>2.309548</td>\n",
              "      <td>5.273173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.152823</td>\n",
              "      <td>0.807005</td>\n",
              "      <td>-0.649554</td>\n",
              "      <td>-0.793097</td>\n",
              "      <td>-0.194764</td>\n",
              "      <td>1.148900</td>\n",
              "      <td>-0.880038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.797195</td>\n",
              "      <td>-0.382299</td>\n",
              "      <td>0.697448</td>\n",
              "      <td>0.481446</td>\n",
              "      <td>0.267127</td>\n",
              "      <td>-0.316789</td>\n",
              "      <td>0.063962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.407079</td>\n",
              "      <td>0.003535</td>\n",
              "      <td>0.649205</td>\n",
              "      <td>0.271346</td>\n",
              "      <td>0.291866</td>\n",
              "      <td>-0.083678</td>\n",
              "      <td>-0.113309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20375</th>\n",
              "      <td>0.403829</td>\n",
              "      <td>0.691195</td>\n",
              "      <td>0.278173</td>\n",
              "      <td>-0.034130</td>\n",
              "      <td>0.275256</td>\n",
              "      <td>0.233534</td>\n",
              "      <td>-0.471766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20376</th>\n",
              "      <td>-0.983975</td>\n",
              "      <td>0.232755</td>\n",
              "      <td>0.513248</td>\n",
              "      <td>0.229956</td>\n",
              "      <td>0.255983</td>\n",
              "      <td>-0.050738</td>\n",
              "      <td>-0.235206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20377</th>\n",
              "      <td>-0.939819</td>\n",
              "      <td>4.516228</td>\n",
              "      <td>-1.403314</td>\n",
              "      <td>-3.811870</td>\n",
              "      <td>3.241070</td>\n",
              "      <td>2.156336</td>\n",
              "      <td>-1.429125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378</th>\n",
              "      <td>-0.149213</td>\n",
              "      <td>0.135246</td>\n",
              "      <td>0.767912</td>\n",
              "      <td>-0.606392</td>\n",
              "      <td>0.404447</td>\n",
              "      <td>0.819223</td>\n",
              "      <td>-0.147911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379</th>\n",
              "      <td>1.184504</td>\n",
              "      <td>0.357866</td>\n",
              "      <td>0.519680</td>\n",
              "      <td>0.584021</td>\n",
              "      <td>0.354873</td>\n",
              "      <td>-0.387292</td>\n",
              "      <td>-0.284192</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20380 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01b72ce8-ba68-40fa-9e23-540a72a92f8e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01b72ce8-ba68-40fa-9e23-540a72a92f8e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01b72ce8-ba68-40fa-9e23-540a72a92f8e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train.loc[:, train.columns == \"Action\"]\n",
        "train_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "f3QHH-_ROJ5C",
        "outputId": "808ca996-fe26-4ca1-cb1f-671efc3ab7fe"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Action\n",
              "0           0\n",
              "1           4\n",
              "2           0\n",
              "3           0\n",
              "4           1\n",
              "...       ...\n",
              "20375       1\n",
              "20376       4\n",
              "20377       4\n",
              "20378       0\n",
              "20379       0\n",
              "\n",
              "[20380 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52d5a82c-a103-4a71-94bf-ac2dc67c8cc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20375</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20376</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20377</th>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20378</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20379</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20380 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52d5a82c-a103-4a71-94bf-ac2dc67c8cc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52d5a82c-a103-4a71-94bf-ac2dc67c8cc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52d5a82c-a103-4a71-94bf-ac2dc67c8cc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val = val.reset_index(drop=True)\n",
        "val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "m-BebthUNX-q",
        "outputId": "e700837b-d515-490b-c06c-3cd65679fc6a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0     0.820280   0.383292   0.880803   0.301167   1.006691     72.592552   \n",
              "1     2.775952   7.088034   6.157887  -1.347936   9.485606     98.169571   \n",
              "2     0.770258   5.576096   7.787141   1.945289   9.773257     78.519058   \n",
              "3     2.039660  11.510124   0.025139   0.781707  11.536666     86.114746   \n",
              "4     0.759667   9.654618   5.208586  -1.112107  11.026232     95.788704   \n",
              "...        ...        ...        ...        ...        ...           ...   \n",
              "5091  2.050196   0.393420   0.879338   0.298238   1.008445     72.798058   \n",
              "5092  2.530211   1.045069   6.348226   1.792060   6.678594     74.435150   \n",
              "5093  3.128604   1.928530   9.556456   1.526304   9.867861     81.102097   \n",
              "5094  3.157906   5.519832   7.926005   1.814805   9.827697     79.358559   \n",
              "5095  0.828782   4.455609   8.566454   1.983596   9.857548     78.391335   \n",
              "\n",
              "       Phi (deg)  Action  \n",
              "0      66.483147       1  \n",
              "1      40.983204       4  \n",
              "2      54.394894       2  \n",
              "3       0.125139       4  \n",
              "4      28.346491       4  \n",
              "...          ...     ...  \n",
              "5091   65.896019       1  \n",
              "5092   80.651596       4  \n",
              "5093   78.590721       0  \n",
              "5094   55.145859       2  \n",
              "5095   62.520023       2  \n",
              "\n",
              "[5096 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-870cb337-96c2-45be-b75f-ee7489547490\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.820280</td>\n",
              "      <td>0.383292</td>\n",
              "      <td>0.880803</td>\n",
              "      <td>0.301167</td>\n",
              "      <td>1.006691</td>\n",
              "      <td>72.592552</td>\n",
              "      <td>66.483147</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.775952</td>\n",
              "      <td>7.088034</td>\n",
              "      <td>6.157887</td>\n",
              "      <td>-1.347936</td>\n",
              "      <td>9.485606</td>\n",
              "      <td>98.169571</td>\n",
              "      <td>40.983204</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.770258</td>\n",
              "      <td>5.576096</td>\n",
              "      <td>7.787141</td>\n",
              "      <td>1.945289</td>\n",
              "      <td>9.773257</td>\n",
              "      <td>78.519058</td>\n",
              "      <td>54.394894</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.039660</td>\n",
              "      <td>11.510124</td>\n",
              "      <td>0.025139</td>\n",
              "      <td>0.781707</td>\n",
              "      <td>11.536666</td>\n",
              "      <td>86.114746</td>\n",
              "      <td>0.125139</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.759667</td>\n",
              "      <td>9.654618</td>\n",
              "      <td>5.208586</td>\n",
              "      <td>-1.112107</td>\n",
              "      <td>11.026232</td>\n",
              "      <td>95.788704</td>\n",
              "      <td>28.346491</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5091</th>\n",
              "      <td>2.050196</td>\n",
              "      <td>0.393420</td>\n",
              "      <td>0.879338</td>\n",
              "      <td>0.298238</td>\n",
              "      <td>1.008445</td>\n",
              "      <td>72.798058</td>\n",
              "      <td>65.896019</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5092</th>\n",
              "      <td>2.530211</td>\n",
              "      <td>1.045069</td>\n",
              "      <td>6.348226</td>\n",
              "      <td>1.792060</td>\n",
              "      <td>6.678594</td>\n",
              "      <td>74.435150</td>\n",
              "      <td>80.651596</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5093</th>\n",
              "      <td>3.128604</td>\n",
              "      <td>1.928530</td>\n",
              "      <td>9.556456</td>\n",
              "      <td>1.526304</td>\n",
              "      <td>9.867861</td>\n",
              "      <td>81.102097</td>\n",
              "      <td>78.590721</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5094</th>\n",
              "      <td>3.157906</td>\n",
              "      <td>5.519832</td>\n",
              "      <td>7.926005</td>\n",
              "      <td>1.814805</td>\n",
              "      <td>9.827697</td>\n",
              "      <td>79.358559</td>\n",
              "      <td>55.145859</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5095</th>\n",
              "      <td>0.828782</td>\n",
              "      <td>4.455609</td>\n",
              "      <td>8.566454</td>\n",
              "      <td>1.983596</td>\n",
              "      <td>9.857548</td>\n",
              "      <td>78.391335</td>\n",
              "      <td>62.520023</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5096 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-870cb337-96c2-45be-b75f-ee7489547490')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-870cb337-96c2-45be-b75f-ee7489547490 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-870cb337-96c2-45be-b75f-ee7489547490');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test  = test.reset_index(drop=True)\n",
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "N3q256opNYvS",
        "outputId": "36252921-9370-4fee-a6a5-086472e1d1bc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Time (s)   X (m/s2)   Y (m/s2)   Z (m/s2)   R (m/s2)   Theta (deg)  \\\n",
              "0     3.108875   2.280477   9.440337   0.653617   9.733846     86.149757   \n",
              "1     1.729461   2.408567   8.708909   4.019865   9.889671     66.016663   \n",
              "2     2.490007   8.248025   5.345055   0.553061   9.844054     86.779305   \n",
              "3     0.029844  -0.022745   7.977480   5.479131   9.677891     55.517864   \n",
              "4     4.750331   0.360473   0.939742   0.540831   1.142609     61.749329   \n",
              "...        ...        ...        ...        ...        ...           ...   \n",
              "6364  2.589941   0.703895   8.245630   5.260061   9.805821     57.559578   \n",
              "6365  4.908728   0.913388   8.374918   2.127248   8.688999     75.828751   \n",
              "6366  2.650183   1.719037  10.061633   1.213860  10.279348     83.218277   \n",
              "6367  4.740317   3.197456   8.890868   2.536657   9.782939     74.971832   \n",
              "6368  3.880287   1.880645   9.471462   1.715446   9.807557     79.926544   \n",
              "\n",
              "       Phi (deg)  Action  \n",
              "0      76.419388       4  \n",
              "1      74.540497       3  \n",
              "2      32.944874       2  \n",
              "3      90.163361       3  \n",
              "4      69.013863       2  \n",
              "...          ...     ...  \n",
              "6364   85.120728       3  \n",
              "6365   83.775787       0  \n",
              "6366   80.304588       4  \n",
              "6367   70.219704       2  \n",
              "6368   78.769470       0  \n",
              "\n",
              "[6369 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0bd08179-67e4-4324-ae92-65f1a159d0f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time (s)</th>\n",
              "      <th>X (m/s2)</th>\n",
              "      <th>Y (m/s2)</th>\n",
              "      <th>Z (m/s2)</th>\n",
              "      <th>R (m/s2)</th>\n",
              "      <th>Theta (deg)</th>\n",
              "      <th>Phi (deg)</th>\n",
              "      <th>Action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.108875</td>\n",
              "      <td>2.280477</td>\n",
              "      <td>9.440337</td>\n",
              "      <td>0.653617</td>\n",
              "      <td>9.733846</td>\n",
              "      <td>86.149757</td>\n",
              "      <td>76.419388</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.729461</td>\n",
              "      <td>2.408567</td>\n",
              "      <td>8.708909</td>\n",
              "      <td>4.019865</td>\n",
              "      <td>9.889671</td>\n",
              "      <td>66.016663</td>\n",
              "      <td>74.540497</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.490007</td>\n",
              "      <td>8.248025</td>\n",
              "      <td>5.345055</td>\n",
              "      <td>0.553061</td>\n",
              "      <td>9.844054</td>\n",
              "      <td>86.779305</td>\n",
              "      <td>32.944874</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.029844</td>\n",
              "      <td>-0.022745</td>\n",
              "      <td>7.977480</td>\n",
              "      <td>5.479131</td>\n",
              "      <td>9.677891</td>\n",
              "      <td>55.517864</td>\n",
              "      <td>90.163361</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.750331</td>\n",
              "      <td>0.360473</td>\n",
              "      <td>0.939742</td>\n",
              "      <td>0.540831</td>\n",
              "      <td>1.142609</td>\n",
              "      <td>61.749329</td>\n",
              "      <td>69.013863</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6364</th>\n",
              "      <td>2.589941</td>\n",
              "      <td>0.703895</td>\n",
              "      <td>8.245630</td>\n",
              "      <td>5.260061</td>\n",
              "      <td>9.805821</td>\n",
              "      <td>57.559578</td>\n",
              "      <td>85.120728</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6365</th>\n",
              "      <td>4.908728</td>\n",
              "      <td>0.913388</td>\n",
              "      <td>8.374918</td>\n",
              "      <td>2.127248</td>\n",
              "      <td>8.688999</td>\n",
              "      <td>75.828751</td>\n",
              "      <td>83.775787</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6366</th>\n",
              "      <td>2.650183</td>\n",
              "      <td>1.719037</td>\n",
              "      <td>10.061633</td>\n",
              "      <td>1.213860</td>\n",
              "      <td>10.279348</td>\n",
              "      <td>83.218277</td>\n",
              "      <td>80.304588</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6367</th>\n",
              "      <td>4.740317</td>\n",
              "      <td>3.197456</td>\n",
              "      <td>8.890868</td>\n",
              "      <td>2.536657</td>\n",
              "      <td>9.782939</td>\n",
              "      <td>74.971832</td>\n",
              "      <td>70.219704</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6368</th>\n",
              "      <td>3.880287</td>\n",
              "      <td>1.880645</td>\n",
              "      <td>9.471462</td>\n",
              "      <td>1.715446</td>\n",
              "      <td>9.807557</td>\n",
              "      <td>79.926544</td>\n",
              "      <td>78.769470</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6369 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0bd08179-67e4-4324-ae92-65f1a159d0f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0bd08179-67e4-4324-ae92-65f1a159d0f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0bd08179-67e4-4324-ae92-65f1a159d0f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_x = val.loc[:, val.columns != \"Action\"]\n",
        "val_x=(val_x-val_x.mean())/val_x.std() #normalize\n",
        "val_y = val.loc[:, val.columns == \"Action\"]\n",
        "test_x = test.loc[:, test.columns != \"Action\"]\n",
        "test_x=(test_x-test_x.mean())/test_x.std() #normalize\n",
        "test_y = test.loc[:, test.columns == \"Action\"]"
      ],
      "metadata": {
        "id": "S72VVdcxOcay"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pytorch Dataset Preparation"
      ],
      "metadata": {
        "id": "BMPZ_LyKbBCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2mBaMLdJKdi",
        "outputId": "5486df6b-4a84-4675-e849-afb239d4adb5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [4],\n",
              "       [0],\n",
              "       ...,\n",
              "       [4],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.values.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K51PeBnrJadl",
        "outputId": "8c53e08c-7cd8-41c4-8b8c-a052c0cd5f9c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 4, 0, ..., 4, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BasketballDatasetTrain(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_train=torch.tensor(train_x.values,dtype=torch.float32)\n",
        "    self.y_train=torch.tensor(train_y.values.flatten(),dtype=torch.float32)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y_train)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x_train[idx],self.y_train[idx]\n",
        "\n",
        "class BasketballDatasetVal(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_val=torch.tensor(val_x.values,dtype=torch.float32)\n",
        "    self.y_val=torch.tensor(val_y.values.flatten(),dtype=torch.float32)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y_val)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x_val[idx],self.y_val[idx]\n",
        "\n",
        "class BasketballDatasetTest(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_test=torch.tensor(test_x.values,dtype=torch.float32)\n",
        "    self.y_test=torch.tensor(test_y.values.flatten(),dtype=torch.float32)\n",
        " \n",
        "  def __len__(self):\n",
        "    return len(self.y_test)\n",
        "   \n",
        "  def __getitem__(self,idx):\n",
        "    return self.x_test[idx],self.y_test[idx]"
      ],
      "metadata": {
        "id": "7OP2dCSVVp0x"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_data=BasketballDatasetTrain()\n",
        "val_data=BasketballDatasetVal()\n",
        "test_data=BasketballDatasetTest()\n",
        "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "hxwDswoaelwt"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print some dataloader values to make sure dataloader is \n",
        "#working as intended\n",
        "#We want to make sure  X and y look something like\n",
        "#torch.Size([64, 7]) torch.Size([64])\n",
        "#as we want to pass properly sized \n",
        "#tensors of features and their labels respectively\n",
        "#to the NN.\n",
        "for i, (data, labels) in enumerate(train_dataloader):\n",
        "  print(data.shape, labels.shape)\n",
        "  print(data,labels)\n",
        "  break;"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWXy2VbThJ8K",
        "outputId": "063ad0a1-39f5-426f-9ce5-57bf0d1ab991"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 7]) torch.Size([64])\n",
            "tensor([[ 1.3578e-02, -8.7743e-01, -1.3382e+00, -3.3005e-01, -1.6709e+00,\n",
            "          1.1978e-01,  3.9799e-01],\n",
            "        [-8.0754e-01,  3.3230e+00, -2.5921e+00, -3.4326e+00,  2.2877e+00,\n",
            "          2.3095e+00,  5.2732e+00],\n",
            "        [ 1.5282e-01,  8.0700e-01, -6.4955e-01, -7.9310e-01, -1.9476e-01,\n",
            "          1.1489e+00, -8.8004e-01],\n",
            "        [-7.9720e-01, -3.8230e-01,  6.9745e-01,  4.8145e-01,  2.6713e-01,\n",
            "         -3.1679e-01,  6.3962e-02],\n",
            "        [-4.0708e-01,  3.5350e-03,  6.4921e-01,  2.7135e-01,  2.9187e-01,\n",
            "         -8.3678e-02, -1.1331e-01],\n",
            "        [ 2.0360e+00,  2.6096e-01,  5.1149e-01, -7.7375e-01,  2.4862e-01,\n",
            "          1.0134e+00, -2.4716e-01],\n",
            "        [-3.8239e-02, -4.8821e-01,  2.3519e-01,  1.1630e+00,  7.6714e-03,\n",
            "         -1.3203e+00,  7.0463e-02],\n",
            "        [-8.1751e-01,  4.4607e-01,  4.5185e-01,  1.3053e-01,  2.8989e-01,\n",
            "          6.3773e-02, -3.3442e-01],\n",
            "        [-1.5602e-01, -2.0018e-01,  6.7991e-01, -2.8337e-01,  2.3010e-01,\n",
            "          4.9256e-01, -2.0090e-02],\n",
            "        [ 1.2796e+00,  1.0332e+00,  3.8840e-01,  1.2589e+00,  7.2111e-01,\n",
            "         -8.6107e-01, -5.5068e-01],\n",
            "        [ 1.1879e+00, -8.2513e-01, -1.3536e+00, -3.3468e-01, -1.6851e+00,\n",
            "          1.3743e-01,  1.6757e-01],\n",
            "        [-8.8231e-01,  1.0074e+00, -2.1305e+00, -2.1680e+00,  1.0267e-01,\n",
            "          2.7333e+00,  5.2196e+00],\n",
            "        [-5.6996e-01,  4.5897e-01, -2.2385e-01,  6.5105e-01, -1.0667e-01,\n",
            "         -7.3725e-01, -5.5417e-01],\n",
            "        [ 9.5203e-02, -1.3112e+00,  1.2321e-01, -3.2386e-01, -2.9992e-01,\n",
            "          5.1659e-01,  5.6917e-01],\n",
            "        [-9.6025e-01,  9.2131e-01, -1.6094e+00, -9.2672e-01, -3.0889e-01,\n",
            "          1.3829e+00,  5.5309e+00],\n",
            "        [-1.9663e-01,  5.7328e-01,  3.9483e-01,  6.5960e-01,  3.7124e-01,\n",
            "         -4.5844e-01, -3.9681e-01],\n",
            "        [-9.5705e-01,  3.9538e-02,  6.0739e-01,  3.7932e-01,  2.8032e-01,\n",
            "         -2.0202e-01, -1.3571e-01],\n",
            "        [-5.8347e-01,  7.8600e-01,  2.2174e-01, -4.8871e-03,  2.9155e-01,\n",
            "          2.0573e-01, -5.2139e-01],\n",
            "        [ 9.3662e-01,  7.7041e-02,  8.5153e-01, -1.4000e+00,  5.2777e-01,\n",
            "          1.5613e+00, -1.1190e-01],\n",
            "        [-1.1843e+00, -1.3567e-02,  1.4280e-01,  6.4701e-01, -6.8235e-02,\n",
            "         -7.0293e-01, -2.0697e-01],\n",
            "        [ 2.3441e-01, -9.4785e-01,  2.4385e-02, -5.9774e-02, -4.2738e-01,\n",
            "          1.0097e-01,  3.4889e-01],\n",
            "        [-3.3251e-01, -7.0571e-02,  7.2347e-01,  4.9404e-01,  3.5909e-01,\n",
            "         -2.9213e-01, -7.0457e-02],\n",
            "        [-1.1164e+00,  4.6107e-01,  4.0828e-01, -2.2533e-01,  2.4498e-01,\n",
            "          4.3169e-01, -3.5104e-01],\n",
            "        [ 1.7686e-01, -7.5886e-01, -1.3718e+00, -2.8268e-01, -1.6812e+00,\n",
            "         -3.9779e-01, -1.4717e-01],\n",
            "        [ 1.0693e+00, -9.1573e-02, -1.8595e-02,  2.0205e+00,  2.0818e-01,\n",
            "         -2.2398e+00, -2.0690e-01],\n",
            "        [-2.2396e-01, -1.0417e-01,  6.3576e-01,  1.8227e-01,  2.4112e-01,\n",
            "         -3.9261e-03, -6.8671e-02],\n",
            "        [ 1.9025e+00,  1.0209e+00,  3.7875e-01,  1.6570e+00,  8.0325e-01,\n",
            "         -1.1804e+00, -5.4975e-01],\n",
            "        [-6.8569e-01, -6.3515e-01, -1.5648e+00, -2.5411e-01, -1.6984e+00,\n",
            "         -8.1780e-01, -1.3262e+00],\n",
            "        [-2.3729e-01, -2.7759e-01,  7.2084e-01,  2.8304e-01,  2.8284e-01,\n",
            "         -9.8888e-02,  1.9158e-02],\n",
            "        [-5.0549e-01,  4.2057e-01,  3.8840e-01, -4.8077e-02,  2.1773e-01,\n",
            "          2.3877e-01, -3.4026e-01],\n",
            "        [-6.3105e-01,  8.9043e-02,  8.5036e-01,  2.5920e-01,  4.8473e-01,\n",
            "         -1.6718e-02, -1.1676e-01],\n",
            "        [-3.2557e-01, -2.3919e-01,  7.7025e-01, -3.2791e-01,  2.9971e-01,\n",
            "          5.4183e-01,  7.8060e-03],\n",
            "        [-5.2244e-01,  4.4637e-01,  2.8197e-01,  3.2106e-03,  1.5278e-01,\n",
            "          1.7040e-01, -3.7866e-01],\n",
            "        [-2.6507e-01, -4.5160e-01,  7.7171e-01,  5.2913e-01,  3.2733e-01,\n",
            "         -3.4184e-01,  1.0159e-01],\n",
            "        [-6.9197e-01,  2.4430e+00, -3.0766e+00, -1.5192e+00,  1.3640e+00,\n",
            "          1.3951e+00,  5.0588e+00],\n",
            "        [ 2.2128e+00, -7.4234e-01, -1.3660e+00, -3.9857e-01, -1.6774e+00,\n",
            "          7.9853e-01, -2.0408e-01],\n",
            "        [-2.3840e-02, -6.9133e-01,  8.2346e-01, -3.6660e-01,  2.8523e-01,\n",
            "          5.8176e-01,  2.1193e-01],\n",
            "        [-5.3601e-01,  1.2285e+00, -2.8349e-01, -1.3131e-01,  2.8244e-01,\n",
            "          3.3633e-01, -8.2950e-01],\n",
            "        [-4.1381e-01, -4.2100e-01,  7.5622e-01,  4.1621e-01,  3.0335e-01,\n",
            "         -2.3252e-01,  8.6645e-02],\n",
            "        [-1.0756e+00,  1.4036e-02,  6.4277e-01,  3.1499e-01,  2.9430e-01,\n",
            "         -1.2890e-01, -1.1884e-01],\n",
            "        [ 9.5040e-01, -1.9118e-01,  6.2318e-01,  4.0586e-01,  2.3251e-01,\n",
            "         -2.4907e-01, -3.1554e-02],\n",
            "        [ 3.0248e-01, -2.2869e-01,  7.4101e-01, -1.8709e-01,  2.7909e-01,\n",
            "          3.9426e-01, -9.8984e-05],\n",
            "        [ 1.4897e+00, -8.2088e-01, -1.4114e+00, -2.6851e-01, -1.7258e+00,\n",
            "         -8.4861e-01,  1.0578e-01],\n",
            "        [ 5.7381e-01, -8.2634e-01,  4.0185e-01, -5.1776e-01, -9.8517e-02,\n",
            "          7.7004e-01,  2.7030e-01],\n",
            "        [-5.1897e-01,  6.9210e-01,  3.4659e-01, -3.1036e-01,  3.1526e-01,\n",
            "          5.2418e-01, -4.5258e-01],\n",
            "        [-7.4983e-01,  2.4806e-01,  5.5886e-01,  1.6708e-02,  2.8148e-01,\n",
            "          1.8129e-01, -2.3190e-01],\n",
            "        [-8.3862e-01, -5.6771e-01, -6.5657e-01,  2.9118e+00,  2.2165e-01,\n",
            "         -3.8367e+00, -3.6337e-02],\n",
            "        [ 1.7918e+00, -1.3328e-01,  3.4571e-01, -4.3678e-01, -4.0404e-02,\n",
            "          6.6546e-01, -1.0285e-01],\n",
            "        [-4.1292e-01,  2.1385e-01,  5.0915e-01, -3.9874e-03,  2.2685e-01,\n",
            "          1.9292e-01, -2.2824e-01],\n",
            "        [-9.5345e-01, -4.8941e-01,  8.7814e-01,  1.0859e-02,  3.6428e-01,\n",
            "          2.0232e-01,  1.2558e-01],\n",
            "        [-6.0386e-01, -7.5421e-01, -1.3778e+00, -2.6672e-01, -1.6819e+00,\n",
            "         -5.7179e-01, -1.7797e-01],\n",
            "        [ 1.3061e+00, -1.0097e+00,  1.1268e-01,  2.4304e+00,  3.5932e-01,\n",
            "         -2.5753e+00,  3.8473e-01],\n",
            "        [ 3.3623e-01, -7.9070e-01, -1.3780e+00, -2.1283e-01, -1.6804e+00,\n",
            "         -1.1563e+00, -1.3905e-02],\n",
            "        [-1.1808e+00, -3.5650e-01,  7.2873e-01,  4.3196e-01,  2.9202e-01,\n",
            "         -2.5359e-01,  5.5231e-02],\n",
            "        [ 6.9841e-03,  6.2849e-01,  3.2203e-01, -3.4276e-01,  2.6332e-01,\n",
            "          5.5657e-01, -4.3678e-01],\n",
            "        [-1.3557e-01, -7.6326e-01, -1.3632e+00, -3.5303e-01, -1.6821e+00,\n",
            "          3.3342e-01, -1.1425e-01],\n",
            "        [-2.4750e-01, -2.0648e-01,  6.9862e-01,  3.3613e-01,  2.8485e-01,\n",
            "         -1.5448e-01, -1.4948e-02],\n",
            "        [ 2.7179e-01,  3.5127e-01,  4.8898e-01, -3.9449e-01,  2.5588e-01,\n",
            "          6.1102e-01, -2.8856e-01],\n",
            "        [ 7.7891e-02, -2.2568e-01,  7.2230e-01, -1.1331e-01,  2.6609e-01,\n",
            "          3.1544e-01, -3.6130e-03],\n",
            "        [-9.2979e-01,  3.9846e+00, -1.4349e+00, -5.0837e+00,  3.1779e+00,\n",
            "          2.8245e+00, -1.4322e+00],\n",
            "        [-1.8654e-01,  2.6066e-01,  8.0815e-02,  1.7641e+00,  2.9478e-01,\n",
            "         -1.7702e+00, -3.5763e-01],\n",
            "        [ 4.0695e-02,  6.3540e-02,  5.9599e-01,  3.7752e-01,  2.7844e-01,\n",
            "         -2.0080e-01, -1.4796e-01],\n",
            "        [-1.2181e+00, -7.7424e-01, -1.3670e+00, -3.0717e-01, -1.6850e+00,\n",
            "         -1.5309e-01, -7.3187e-02],\n",
            "        [-4.9189e-01,  6.7259e-01,  3.2028e-01, -3.1801e-01,  2.8585e-01,\n",
            "          5.3120e-01, -4.5309e-01]]) tensor([0., 4., 0., 0., 1., 0., 3., 2., 4., 3., 0., 4., 4., 3., 4., 4., 1., 1.,\n",
            "        0., 4., 3., 4., 2., 4., 3., 4., 0., 4., 3., 4., 4., 4., 4., 3., 4., 0.,\n",
            "        3., 2., 3., 1., 2., 4., 0., 3., 1., 2., 3., 0., 2., 0., 1., 3., 2., 0.,\n",
            "        1., 0., 0., 2., 4., 4., 3., 1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Base RNN"
      ],
      "metadata": {
        "id": "hOPKQwDxTeEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    #this time we'll let our init take arguments for what the \n",
        "    #input/output size and various other hyperparameters can be\n",
        "    def __init__(self, input_size, hidden_size, layer_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "\n",
        "\n",
        "        #number features hidden\n",
        "        self.hidden_size = hidden_size\n",
        "        #number of hidden layers\n",
        "        self.layer_size = layer_size\n",
        "        \n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
        "        #batch_first – If True, then the input and output tensors are provided as \n",
        "        #(batch, seq, feature) instead of (seq, batch, feature).\n",
        "        #Note that this does not apply to hidden or cell states.\n",
        "\n",
        "        #Activation function - relu\n",
        "        self.rnn = nn.RNN(input_size, hidden_size, layer_size, batch_first=True, nonlinearity='relu')\n",
        "        \n",
        "        #We need a final output layer \n",
        "        self.op = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = Variable(torch.zeros(self.layer_size, self.hidden_size))\n",
        "        # One time step on RNN\n",
        "        out, hn = self.rnn(x, h0)\n",
        "        out = self.op(out) \n",
        "        return out"
      ],
      "metadata": {
        "id": "gW3TICH0KE-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code snippet attribution:\n",
        "#https://pytorch.org/tutorials/beginner/basics/intro.html\n",
        "#was used as part of the research process\n",
        "#Modifications were made so that data could be processed as longs,\n",
        "#additional statistics could be reported, \n",
        "#and a separate validate process was created. \n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    end = math.floor(size/batch_size)\n",
        "    #print(size)\n",
        "    #print(end)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.long()) #loss function requires longs\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        current =  batch * len(X)\n",
        "        #When all batches complete\n",
        "        if batch % 100 == 0:\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            #return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "        if (batch>=end): #on last value of enumerate\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(\"epoch over\")\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "\n",
        "#validation\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return correct\n",
        "\n",
        "#test - only use when training/validation are over\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "jNywb14kNX3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll use same loss and SGD as last time\n",
        "input_s = 7 #input features (7 measured values)\n",
        "hidden_s = 265 # hidden features\n",
        "layer_s = 2 # #of hidden layers\n",
        "output_s = 5 #output features - (5 possible actions)\n",
        "\n",
        "model = RNN(input_s,hidden_s,layer_s,output_s).to(device)\n",
        "print(model)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LrLFb7DSz8j",
        "outputId": "fb921d1b-82b0-45cc-936e-00a30bffa4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(\n",
            "  (rnn): RNN(7, 265, num_layers=2, batch_first=True)\n",
            "  (fc): Linear(in_features=265, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measure validation, and stop the NN if learning has stopped\n",
        "#increasing in validation\n",
        "epochs = 100\n",
        "bestval = 0\n",
        "decval = 0\n",
        "\n",
        "loss_rec = [0]\n",
        "acc_rec = [0]\n",
        "epo_rec = [0]\n",
        "#store loss and accuracy every 10 epochs\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    losst, acct = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    #losst = la_tuple[0]\n",
        "    #acct = la_tuple[1]\n",
        "    tempval = validate(val_dataloader, model, loss_fn)\n",
        "    #if 1==1: #test statement\n",
        "    if (t+1) % 10 == 0: #change to desired epoch records factor - e.g. t+1 % 10 every 10 epochs\n",
        "      loss_rec.append(losst)\n",
        "      acc_rec.append(acct)\n",
        "      epo_rec.append(t+1)\n",
        "\n",
        "    if(tempval < bestval):\n",
        "      decval+=1 \n",
        "      if(decval==3):\n",
        "        loss_rec.append(losst)\n",
        "        acc_rec.append(acct)\n",
        "        epo_rec.append(t+1)\n",
        "        print(\"Validation no longer rising. Done!\")\n",
        "        break\n",
        "    else:\n",
        "      bestval=tempval\n",
        "print(\"Max number of epochs hit or validation stop reached. Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb3fnrNuRdBF",
        "outputId": "a0cfda1e-dccb-4a20-b19b-9c5e0d6f0ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.597118  [    0/20380]\n",
            "Train Error: Accuracy: 18.3%\n",
            "loss: 1.608281  [ 6400/20380]\n",
            "Train Error: Accuracy: 25.4%\n",
            "loss: 1.593612  [12800/20380]\n",
            "Train Error: Accuracy: 31.5%\n",
            "loss: 1.565642  [19200/20380]\n",
            "Train Error: Accuracy: 36.3%\n",
            "epoch over\n",
            "loss: 1.564106  [ 8904/20380]\n",
            "Train Error: Accuracy: 36.2%\n",
            "Val Error: \n",
            " Accuracy: 35.9%, Avg loss: 1.580477 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.577291  [    0/20380]\n",
            "Train Error: Accuracy: 36.1%\n",
            "loss: 1.577551  [ 6400/20380]\n",
            "Train Error: Accuracy: 35.9%\n",
            "loss: 1.549389  [12800/20380]\n",
            "Train Error: Accuracy: 40.7%\n",
            "loss: 1.479649  [19200/20380]\n",
            "Train Error: Accuracy: 40.4%\n",
            "epoch over\n",
            "loss: 1.481462  [ 8904/20380]\n",
            "Train Error: Accuracy: 39.2%\n",
            "Val Error: \n",
            " Accuracy: 39.8%, Avg loss: 1.522643 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.522725  [    0/20380]\n",
            "Train Error: Accuracy: 38.7%\n",
            "loss: 1.522195  [ 6400/20380]\n",
            "Train Error: Accuracy: 38.0%\n",
            "loss: 1.455584  [12800/20380]\n",
            "Train Error: Accuracy: 41.0%\n",
            "loss: 1.311666  [19200/20380]\n",
            "Train Error: Accuracy: 42.1%\n",
            "epoch over\n",
            "loss: 1.331613  [ 8904/20380]\n",
            "Train Error: Accuracy: 40.9%\n",
            "Val Error: \n",
            " Accuracy: 42.2%, Avg loss: 1.413632 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.419801  [    0/20380]\n",
            "Train Error: Accuracy: 40.5%\n",
            "loss: 1.437140  [ 6400/20380]\n",
            "Train Error: Accuracy: 42.0%\n",
            "loss: 1.346018  [12800/20380]\n",
            "Train Error: Accuracy: 44.7%\n",
            "loss: 1.168825  [19200/20380]\n",
            "Train Error: Accuracy: 45.4%\n",
            "epoch over\n",
            "loss: 1.218422  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.6%\n",
            "Val Error: \n",
            " Accuracy: 45.1%, Avg loss: 1.320688 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.345523  [    0/20380]\n",
            "Train Error: Accuracy: 43.8%\n",
            "loss: 1.362352  [ 6400/20380]\n",
            "Train Error: Accuracy: 45.8%\n",
            "loss: 1.279605  [12800/20380]\n",
            "Train Error: Accuracy: 46.6%\n",
            "loss: 1.087842  [19200/20380]\n",
            "Train Error: Accuracy: 46.7%\n",
            "epoch over\n",
            "loss: 1.175830  [ 8904/20380]\n",
            "Train Error: Accuracy: 46.1%\n",
            "Val Error: \n",
            " Accuracy: 46.6%, Avg loss: 1.269817 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.305484  [    0/20380]\n",
            "Train Error: Accuracy: 45.2%\n",
            "loss: 1.314304  [ 6400/20380]\n",
            "Train Error: Accuracy: 46.5%\n",
            "loss: 1.246125  [12800/20380]\n",
            "Train Error: Accuracy: 47.0%\n",
            "loss: 1.038793  [19200/20380]\n",
            "Train Error: Accuracy: 47.0%\n",
            "epoch over\n",
            "loss: 1.156076  [ 8904/20380]\n",
            "Train Error: Accuracy: 46.8%\n",
            "Val Error: \n",
            " Accuracy: 47.3%, Avg loss: 1.238739 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.280037  [    0/20380]\n",
            "Train Error: Accuracy: 46.0%\n",
            "loss: 1.283622  [ 6400/20380]\n",
            "Train Error: Accuracy: 46.5%\n",
            "loss: 1.231467  [12800/20380]\n",
            "Train Error: Accuracy: 47.2%\n",
            "loss: 1.003883  [19200/20380]\n",
            "Train Error: Accuracy: 47.4%\n",
            "epoch over\n",
            "loss: 1.135173  [ 8904/20380]\n",
            "Train Error: Accuracy: 47.2%\n",
            "Val Error: \n",
            " Accuracy: 47.4%, Avg loss: 1.213136 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.261855  [    0/20380]\n",
            "Train Error: Accuracy: 46.7%\n",
            "loss: 1.257654  [ 6400/20380]\n",
            "Train Error: Accuracy: 47.3%\n",
            "loss: 1.223715  [12800/20380]\n",
            "Train Error: Accuracy: 47.7%\n",
            "loss: 0.975004  [19200/20380]\n",
            "Train Error: Accuracy: 47.7%\n",
            "epoch over\n",
            "loss: 1.111848  [ 8904/20380]\n",
            "Train Error: Accuracy: 47.8%\n",
            "Val Error: \n",
            " Accuracy: 47.9%, Avg loss: 1.189054 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.245675  [    0/20380]\n",
            "Train Error: Accuracy: 47.4%\n",
            "loss: 1.234647  [ 6400/20380]\n",
            "Train Error: Accuracy: 48.0%\n",
            "loss: 1.218156  [12800/20380]\n",
            "Train Error: Accuracy: 48.0%\n",
            "loss: 0.949652  [19200/20380]\n",
            "Train Error: Accuracy: 48.1%\n",
            "epoch over\n",
            "loss: 1.086504  [ 8904/20380]\n",
            "Train Error: Accuracy: 48.5%\n",
            "Val Error: \n",
            " Accuracy: 48.5%, Avg loss: 1.166004 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.230091  [    0/20380]\n",
            "Train Error: Accuracy: 47.9%\n",
            "loss: 1.215109  [ 6400/20380]\n",
            "Train Error: Accuracy: 49.0%\n",
            "loss: 1.212411  [12800/20380]\n",
            "Train Error: Accuracy: 48.8%\n",
            "loss: 0.927628  [19200/20380]\n",
            "Train Error: Accuracy: 48.7%\n",
            "epoch over\n",
            "loss: 1.062989  [ 8904/20380]\n",
            "Train Error: Accuracy: 49.0%\n",
            "Val Error: \n",
            " Accuracy: 48.9%, Avg loss: 1.144603 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.217587  [    0/20380]\n",
            "Train Error: Accuracy: 48.4%\n",
            "loss: 1.199000  [ 6400/20380]\n",
            "Train Error: Accuracy: 49.9%\n",
            "loss: 1.203333  [12800/20380]\n",
            "Train Error: Accuracy: 49.8%\n",
            "loss: 0.908558  [19200/20380]\n",
            "Train Error: Accuracy: 49.5%\n",
            "epoch over\n",
            "loss: 1.042102  [ 8904/20380]\n",
            "Train Error: Accuracy: 49.9%\n",
            "Val Error: \n",
            " Accuracy: 49.7%, Avg loss: 1.125048 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.208624  [    0/20380]\n",
            "Train Error: Accuracy: 49.1%\n",
            "loss: 1.185072  [ 6400/20380]\n",
            "Train Error: Accuracy: 51.0%\n",
            "loss: 1.191641  [12800/20380]\n",
            "Train Error: Accuracy: 50.7%\n",
            "loss: 0.891888  [19200/20380]\n",
            "Train Error: Accuracy: 50.7%\n",
            "epoch over\n",
            "loss: 1.025015  [ 8904/20380]\n",
            "Train Error: Accuracy: 50.8%\n",
            "Val Error: \n",
            " Accuracy: 50.6%, Avg loss: 1.107239 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.203132  [    0/20380]\n",
            "Train Error: Accuracy: 50.1%\n",
            "loss: 1.173050  [ 6400/20380]\n",
            "Train Error: Accuracy: 52.0%\n",
            "loss: 1.177310  [12800/20380]\n",
            "Train Error: Accuracy: 51.5%\n",
            "loss: 0.876426  [19200/20380]\n",
            "Train Error: Accuracy: 51.5%\n",
            "epoch over\n",
            "loss: 1.009503  [ 8904/20380]\n",
            "Train Error: Accuracy: 51.9%\n",
            "Val Error: \n",
            " Accuracy: 51.7%, Avg loss: 1.091000 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.198573  [    0/20380]\n",
            "Train Error: Accuracy: 51.1%\n",
            "loss: 1.160766  [ 6400/20380]\n",
            "Train Error: Accuracy: 52.9%\n",
            "loss: 1.161896  [12800/20380]\n",
            "Train Error: Accuracy: 52.3%\n",
            "loss: 0.862837  [19200/20380]\n",
            "Train Error: Accuracy: 52.7%\n",
            "epoch over\n",
            "loss: 0.994967  [ 8904/20380]\n",
            "Train Error: Accuracy: 52.9%\n",
            "Val Error: \n",
            " Accuracy: 52.5%, Avg loss: 1.075666 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.194509  [    0/20380]\n",
            "Train Error: Accuracy: 52.2%\n",
            "loss: 1.146714  [ 6400/20380]\n",
            "Train Error: Accuracy: 53.5%\n",
            "loss: 1.146816  [12800/20380]\n",
            "Train Error: Accuracy: 53.0%\n",
            "loss: 0.849528  [19200/20380]\n",
            "Train Error: Accuracy: 53.5%\n",
            "epoch over\n",
            "loss: 0.979276  [ 8904/20380]\n",
            "Train Error: Accuracy: 53.9%\n",
            "Val Error: \n",
            " Accuracy: 53.2%, Avg loss: 1.060508 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.189790  [    0/20380]\n",
            "Train Error: Accuracy: 53.2%\n",
            "loss: 1.131415  [ 6400/20380]\n",
            "Train Error: Accuracy: 54.2%\n",
            "loss: 1.130712  [12800/20380]\n",
            "Train Error: Accuracy: 53.8%\n",
            "loss: 0.835954  [19200/20380]\n",
            "Train Error: Accuracy: 54.4%\n",
            "epoch over\n",
            "loss: 0.963713  [ 8904/20380]\n",
            "Train Error: Accuracy: 54.8%\n",
            "Val Error: \n",
            " Accuracy: 54.2%, Avg loss: 1.046028 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.183170  [    0/20380]\n",
            "Train Error: Accuracy: 54.3%\n",
            "loss: 1.115678  [ 6400/20380]\n",
            "Train Error: Accuracy: 54.9%\n",
            "loss: 1.112971  [12800/20380]\n",
            "Train Error: Accuracy: 54.8%\n",
            "loss: 0.822655  [19200/20380]\n",
            "Train Error: Accuracy: 55.3%\n",
            "epoch over\n",
            "loss: 0.946161  [ 8904/20380]\n",
            "Train Error: Accuracy: 55.7%\n",
            "Val Error: \n",
            " Accuracy: 54.9%, Avg loss: 1.031528 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.175689  [    0/20380]\n",
            "Train Error: Accuracy: 55.4%\n",
            "loss: 1.098724  [ 6400/20380]\n",
            "Train Error: Accuracy: 55.9%\n",
            "loss: 1.095162  [12800/20380]\n",
            "Train Error: Accuracy: 55.9%\n",
            "loss: 0.809113  [19200/20380]\n",
            "Train Error: Accuracy: 56.3%\n",
            "epoch over\n",
            "loss: 0.927824  [ 8904/20380]\n",
            "Train Error: Accuracy: 56.9%\n",
            "Val Error: \n",
            " Accuracy: 56.0%, Avg loss: 1.016817 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.168138  [    0/20380]\n",
            "Train Error: Accuracy: 56.3%\n",
            "loss: 1.080840  [ 6400/20380]\n",
            "Train Error: Accuracy: 56.8%\n",
            "loss: 1.076818  [12800/20380]\n",
            "Train Error: Accuracy: 57.1%\n",
            "loss: 0.794995  [19200/20380]\n",
            "Train Error: Accuracy: 57.3%\n",
            "epoch over\n",
            "loss: 0.909312  [ 8904/20380]\n",
            "Train Error: Accuracy: 58.1%\n",
            "Val Error: \n",
            " Accuracy: 57.1%, Avg loss: 1.002250 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.159460  [    0/20380]\n",
            "Train Error: Accuracy: 57.5%\n",
            "loss: 1.062340  [ 6400/20380]\n",
            "Train Error: Accuracy: 58.0%\n",
            "loss: 1.059420  [12800/20380]\n",
            "Train Error: Accuracy: 58.1%\n",
            "loss: 0.782054  [19200/20380]\n",
            "Train Error: Accuracy: 58.3%\n",
            "epoch over\n",
            "loss: 0.889947  [ 8904/20380]\n",
            "Train Error: Accuracy: 58.9%\n",
            "Val Error: \n",
            " Accuracy: 57.8%, Avg loss: 0.987684 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.150727  [    0/20380]\n",
            "Train Error: Accuracy: 58.6%\n",
            "loss: 1.043298  [ 6400/20380]\n",
            "Train Error: Accuracy: 58.9%\n",
            "loss: 1.041680  [12800/20380]\n",
            "Train Error: Accuracy: 59.0%\n",
            "loss: 0.769877  [19200/20380]\n",
            "Train Error: Accuracy: 59.1%\n",
            "epoch over\n",
            "loss: 0.869560  [ 8904/20380]\n",
            "Train Error: Accuracy: 59.8%\n",
            "Val Error: \n",
            " Accuracy: 58.9%, Avg loss: 0.973592 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 1.141584  [    0/20380]\n",
            "Train Error: Accuracy: 59.4%\n",
            "loss: 1.025351  [ 6400/20380]\n",
            "Train Error: Accuracy: 59.8%\n",
            "loss: 1.024778  [12800/20380]\n",
            "Train Error: Accuracy: 60.0%\n",
            "loss: 0.758053  [19200/20380]\n",
            "Train Error: Accuracy: 60.0%\n",
            "epoch over\n",
            "loss: 0.848993  [ 8904/20380]\n",
            "Train Error: Accuracy: 60.5%\n",
            "Val Error: \n",
            " Accuracy: 60.0%, Avg loss: 0.960280 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.133246  [    0/20380]\n",
            "Train Error: Accuracy: 60.1%\n",
            "loss: 1.007525  [ 6400/20380]\n",
            "Train Error: Accuracy: 60.7%\n",
            "loss: 1.007827  [12800/20380]\n",
            "Train Error: Accuracy: 60.8%\n",
            "loss: 0.746548  [19200/20380]\n",
            "Train Error: Accuracy: 60.9%\n",
            "epoch over\n",
            "loss: 0.829414  [ 8904/20380]\n",
            "Train Error: Accuracy: 61.1%\n",
            "Val Error: \n",
            " Accuracy: 60.4%, Avg loss: 0.947647 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.125324  [    0/20380]\n",
            "Train Error: Accuracy: 60.7%\n",
            "loss: 0.990551  [ 6400/20380]\n",
            "Train Error: Accuracy: 61.3%\n",
            "loss: 0.992733  [12800/20380]\n",
            "Train Error: Accuracy: 61.3%\n",
            "loss: 0.736155  [19200/20380]\n",
            "Train Error: Accuracy: 61.5%\n",
            "epoch over\n",
            "loss: 0.809444  [ 8904/20380]\n",
            "Train Error: Accuracy: 61.8%\n",
            "Val Error: \n",
            " Accuracy: 61.1%, Avg loss: 0.935270 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.117973  [    0/20380]\n",
            "Train Error: Accuracy: 61.4%\n",
            "loss: 0.974164  [ 6400/20380]\n",
            "Train Error: Accuracy: 61.9%\n",
            "loss: 0.978779  [12800/20380]\n",
            "Train Error: Accuracy: 61.9%\n",
            "loss: 0.726315  [19200/20380]\n",
            "Train Error: Accuracy: 62.0%\n",
            "epoch over\n",
            "loss: 0.791279  [ 8904/20380]\n",
            "Train Error: Accuracy: 62.5%\n",
            "Val Error: \n",
            " Accuracy: 61.6%, Avg loss: 0.924031 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 1.111143  [    0/20380]\n",
            "Train Error: Accuracy: 62.0%\n",
            "loss: 0.958964  [ 6400/20380]\n",
            "Train Error: Accuracy: 62.5%\n",
            "loss: 0.965914  [12800/20380]\n",
            "Train Error: Accuracy: 62.6%\n",
            "loss: 0.716626  [19200/20380]\n",
            "Train Error: Accuracy: 62.8%\n",
            "epoch over\n",
            "loss: 0.774118  [ 8904/20380]\n",
            "Train Error: Accuracy: 62.9%\n",
            "Val Error: \n",
            " Accuracy: 62.2%, Avg loss: 0.913233 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 1.102371  [    0/20380]\n",
            "Train Error: Accuracy: 62.6%\n",
            "loss: 0.945029  [ 6400/20380]\n",
            "Train Error: Accuracy: 63.2%\n",
            "loss: 0.952426  [12800/20380]\n",
            "Train Error: Accuracy: 63.1%\n",
            "loss: 0.707138  [19200/20380]\n",
            "Train Error: Accuracy: 63.3%\n",
            "epoch over\n",
            "loss: 0.758558  [ 8904/20380]\n",
            "Train Error: Accuracy: 63.5%\n",
            "Val Error: \n",
            " Accuracy: 62.6%, Avg loss: 0.902952 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.095010  [    0/20380]\n",
            "Train Error: Accuracy: 63.2%\n",
            "loss: 0.932275  [ 6400/20380]\n",
            "Train Error: Accuracy: 63.8%\n",
            "loss: 0.939695  [12800/20380]\n",
            "Train Error: Accuracy: 63.7%\n",
            "loss: 0.698344  [19200/20380]\n",
            "Train Error: Accuracy: 63.9%\n",
            "epoch over\n",
            "loss: 0.742427  [ 8904/20380]\n",
            "Train Error: Accuracy: 64.0%\n",
            "Val Error: \n",
            " Accuracy: 63.1%, Avg loss: 0.893205 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 1.088570  [    0/20380]\n",
            "Train Error: Accuracy: 63.7%\n",
            "loss: 0.920011  [ 6400/20380]\n",
            "Train Error: Accuracy: 64.3%\n",
            "loss: 0.926483  [12800/20380]\n",
            "Train Error: Accuracy: 64.3%\n",
            "loss: 0.690551  [19200/20380]\n",
            "Train Error: Accuracy: 64.4%\n",
            "epoch over\n",
            "loss: 0.728095  [ 8904/20380]\n",
            "Train Error: Accuracy: 64.6%\n",
            "Val Error: \n",
            " Accuracy: 63.7%, Avg loss: 0.884544 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 1.080804  [    0/20380]\n",
            "Train Error: Accuracy: 64.2%\n",
            "loss: 0.908282  [ 6400/20380]\n",
            "Train Error: Accuracy: 64.8%\n",
            "loss: 0.913752  [12800/20380]\n",
            "Train Error: Accuracy: 64.8%\n",
            "loss: 0.682714  [19200/20380]\n",
            "Train Error: Accuracy: 64.8%\n",
            "epoch over\n",
            "loss: 0.715384  [ 8904/20380]\n",
            "Train Error: Accuracy: 65.2%\n",
            "Val Error: \n",
            " Accuracy: 64.3%, Avg loss: 0.875553 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 1.073812  [    0/20380]\n",
            "Train Error: Accuracy: 64.6%\n",
            "loss: 0.898118  [ 6400/20380]\n",
            "Train Error: Accuracy: 65.4%\n",
            "loss: 0.901967  [12800/20380]\n",
            "Train Error: Accuracy: 65.3%\n",
            "loss: 0.674462  [19200/20380]\n",
            "Train Error: Accuracy: 65.4%\n",
            "epoch over\n",
            "loss: 0.703548  [ 8904/20380]\n",
            "Train Error: Accuracy: 65.8%\n",
            "Val Error: \n",
            " Accuracy: 64.6%, Avg loss: 0.867305 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 1.065578  [    0/20380]\n",
            "Train Error: Accuracy: 65.2%\n",
            "loss: 0.888474  [ 6400/20380]\n",
            "Train Error: Accuracy: 65.9%\n",
            "loss: 0.888273  [12800/20380]\n",
            "Train Error: Accuracy: 65.8%\n",
            "loss: 0.666906  [19200/20380]\n",
            "Train Error: Accuracy: 65.8%\n",
            "epoch over\n",
            "loss: 0.692332  [ 8904/20380]\n",
            "Train Error: Accuracy: 66.4%\n",
            "Val Error: \n",
            " Accuracy: 65.1%, Avg loss: 0.859625 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 1.058812  [    0/20380]\n",
            "Train Error: Accuracy: 65.6%\n",
            "loss: 0.878149  [ 6400/20380]\n",
            "Train Error: Accuracy: 66.6%\n",
            "loss: 0.874634  [12800/20380]\n",
            "Train Error: Accuracy: 66.3%\n",
            "loss: 0.659718  [19200/20380]\n",
            "Train Error: Accuracy: 66.3%\n",
            "epoch over\n",
            "loss: 0.682026  [ 8904/20380]\n",
            "Train Error: Accuracy: 66.9%\n",
            "Val Error: \n",
            " Accuracy: 65.4%, Avg loss: 0.851952 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 1.053058  [    0/20380]\n",
            "Train Error: Accuracy: 65.9%\n",
            "loss: 0.868932  [ 6400/20380]\n",
            "Train Error: Accuracy: 67.1%\n",
            "loss: 0.861160  [12800/20380]\n",
            "Train Error: Accuracy: 66.8%\n",
            "loss: 0.653146  [19200/20380]\n",
            "Train Error: Accuracy: 66.7%\n",
            "epoch over\n",
            "loss: 0.669407  [ 8904/20380]\n",
            "Train Error: Accuracy: 67.3%\n",
            "Val Error: \n",
            " Accuracy: 65.9%, Avg loss: 0.844780 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 1.045474  [    0/20380]\n",
            "Train Error: Accuracy: 66.3%\n",
            "loss: 0.859352  [ 6400/20380]\n",
            "Train Error: Accuracy: 67.8%\n",
            "loss: 0.847372  [12800/20380]\n",
            "Train Error: Accuracy: 67.3%\n",
            "loss: 0.646168  [19200/20380]\n",
            "Train Error: Accuracy: 67.2%\n",
            "epoch over\n",
            "loss: 0.657761  [ 8904/20380]\n",
            "Train Error: Accuracy: 67.8%\n",
            "Val Error: \n",
            " Accuracy: 66.3%, Avg loss: 0.837754 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 1.040070  [    0/20380]\n",
            "Train Error: Accuracy: 66.6%\n",
            "loss: 0.848802  [ 6400/20380]\n",
            "Train Error: Accuracy: 68.4%\n",
            "loss: 0.834360  [12800/20380]\n",
            "Train Error: Accuracy: 67.8%\n",
            "loss: 0.639128  [19200/20380]\n",
            "Train Error: Accuracy: 67.6%\n",
            "epoch over\n",
            "loss: 0.647592  [ 8904/20380]\n",
            "Train Error: Accuracy: 68.2%\n",
            "Val Error: \n",
            " Accuracy: 66.6%, Avg loss: 0.830987 \n",
            "\n",
            "Epoch 37\n",
            "-------------------------------\n",
            "loss: 1.031941  [    0/20380]\n",
            "Train Error: Accuracy: 66.9%\n",
            "loss: 0.837316  [ 6400/20380]\n",
            "Train Error: Accuracy: 68.8%\n",
            "loss: 0.820111  [12800/20380]\n",
            "Train Error: Accuracy: 68.4%\n",
            "loss: 0.632207  [19200/20380]\n",
            "Train Error: Accuracy: 68.0%\n",
            "epoch over\n",
            "loss: 0.635957  [ 8904/20380]\n",
            "Train Error: Accuracy: 68.9%\n",
            "Val Error: \n",
            " Accuracy: 67.0%, Avg loss: 0.824612 \n",
            "\n",
            "Epoch 38\n",
            "-------------------------------\n",
            "loss: 1.027367  [    0/20380]\n",
            "Train Error: Accuracy: 67.2%\n",
            "loss: 0.827143  [ 6400/20380]\n",
            "Train Error: Accuracy: 69.4%\n",
            "loss: 0.804982  [12800/20380]\n",
            "Train Error: Accuracy: 69.0%\n",
            "loss: 0.623713  [19200/20380]\n",
            "Train Error: Accuracy: 68.5%\n",
            "epoch over\n",
            "loss: 0.623882  [ 8904/20380]\n",
            "Train Error: Accuracy: 69.3%\n",
            "Val Error: \n",
            " Accuracy: 67.4%, Avg loss: 0.818154 \n",
            "\n",
            "Epoch 39\n",
            "-------------------------------\n",
            "loss: 1.021727  [    0/20380]\n",
            "Train Error: Accuracy: 67.7%\n",
            "loss: 0.816781  [ 6400/20380]\n",
            "Train Error: Accuracy: 70.0%\n",
            "loss: 0.791036  [12800/20380]\n",
            "Train Error: Accuracy: 69.5%\n",
            "loss: 0.615381  [19200/20380]\n",
            "Train Error: Accuracy: 68.8%\n",
            "epoch over\n",
            "loss: 0.610868  [ 8904/20380]\n",
            "Train Error: Accuracy: 69.8%\n",
            "Val Error: \n",
            " Accuracy: 67.9%, Avg loss: 0.812530 \n",
            "\n",
            "Epoch 40\n",
            "-------------------------------\n",
            "loss: 1.016966  [    0/20380]\n",
            "Train Error: Accuracy: 68.0%\n",
            "loss: 0.807395  [ 6400/20380]\n",
            "Train Error: Accuracy: 70.5%\n",
            "loss: 0.779214  [12800/20380]\n",
            "Train Error: Accuracy: 70.0%\n",
            "loss: 0.608252  [19200/20380]\n",
            "Train Error: Accuracy: 69.4%\n",
            "epoch over\n",
            "loss: 0.601714  [ 8904/20380]\n",
            "Train Error: Accuracy: 70.3%\n",
            "Val Error: \n",
            " Accuracy: 68.3%, Avg loss: 0.806267 \n",
            "\n",
            "Epoch 41\n",
            "-------------------------------\n",
            "loss: 1.009841  [    0/20380]\n",
            "Train Error: Accuracy: 68.3%\n",
            "loss: 0.799686  [ 6400/20380]\n",
            "Train Error: Accuracy: 70.9%\n",
            "loss: 0.765198  [12800/20380]\n",
            "Train Error: Accuracy: 70.3%\n",
            "loss: 0.600770  [19200/20380]\n",
            "Train Error: Accuracy: 69.8%\n",
            "epoch over\n",
            "loss: 0.590636  [ 8904/20380]\n",
            "Train Error: Accuracy: 70.7%\n",
            "Val Error: \n",
            " Accuracy: 68.5%, Avg loss: 0.800908 \n",
            "\n",
            "Epoch 42\n",
            "-------------------------------\n",
            "loss: 1.003064  [    0/20380]\n",
            "Train Error: Accuracy: 68.5%\n",
            "loss: 0.790218  [ 6400/20380]\n",
            "Train Error: Accuracy: 71.2%\n",
            "loss: 0.751480  [12800/20380]\n",
            "Train Error: Accuracy: 70.5%\n",
            "loss: 0.593797  [19200/20380]\n",
            "Train Error: Accuracy: 70.1%\n",
            "epoch over\n",
            "loss: 0.576931  [ 8904/20380]\n",
            "Train Error: Accuracy: 71.1%\n",
            "Val Error: \n",
            " Accuracy: 68.9%, Avg loss: 0.795683 \n",
            "\n",
            "Epoch 43\n",
            "-------------------------------\n",
            "loss: 0.996329  [    0/20380]\n",
            "Train Error: Accuracy: 68.8%\n",
            "loss: 0.782420  [ 6400/20380]\n",
            "Train Error: Accuracy: 71.7%\n",
            "loss: 0.738091  [12800/20380]\n",
            "Train Error: Accuracy: 71.0%\n",
            "loss: 0.584988  [19200/20380]\n",
            "Train Error: Accuracy: 70.5%\n",
            "epoch over\n",
            "loss: 0.568230  [ 8904/20380]\n",
            "Train Error: Accuracy: 71.5%\n",
            "Val Error: \n",
            " Accuracy: 69.2%, Avg loss: 0.791102 \n",
            "\n",
            "Epoch 44\n",
            "-------------------------------\n",
            "loss: 0.991889  [    0/20380]\n",
            "Train Error: Accuracy: 69.2%\n",
            "loss: 0.774567  [ 6400/20380]\n",
            "Train Error: Accuracy: 72.0%\n",
            "loss: 0.726941  [12800/20380]\n",
            "Train Error: Accuracy: 71.3%\n",
            "loss: 0.576861  [19200/20380]\n",
            "Train Error: Accuracy: 70.9%\n",
            "epoch over\n",
            "loss: 0.558478  [ 8904/20380]\n",
            "Train Error: Accuracy: 71.8%\n",
            "Val Error: \n",
            " Accuracy: 69.5%, Avg loss: 0.786526 \n",
            "\n",
            "Epoch 45\n",
            "-------------------------------\n",
            "loss: 0.987104  [    0/20380]\n",
            "Train Error: Accuracy: 69.4%\n",
            "loss: 0.764983  [ 6400/20380]\n",
            "Train Error: Accuracy: 72.3%\n",
            "loss: 0.714070  [12800/20380]\n",
            "Train Error: Accuracy: 71.6%\n",
            "loss: 0.567916  [19200/20380]\n",
            "Train Error: Accuracy: 71.2%\n",
            "epoch over\n",
            "loss: 0.548304  [ 8904/20380]\n",
            "Train Error: Accuracy: 72.1%\n",
            "Val Error: \n",
            " Accuracy: 69.7%, Avg loss: 0.783139 \n",
            "\n",
            "Epoch 46\n",
            "-------------------------------\n",
            "loss: 0.984275  [    0/20380]\n",
            "Train Error: Accuracy: 69.5%\n",
            "loss: 0.758605  [ 6400/20380]\n",
            "Train Error: Accuracy: 72.6%\n",
            "loss: 0.704798  [12800/20380]\n",
            "Train Error: Accuracy: 71.9%\n",
            "loss: 0.558078  [19200/20380]\n",
            "Train Error: Accuracy: 71.6%\n",
            "epoch over\n",
            "loss: 0.538398  [ 8904/20380]\n",
            "Train Error: Accuracy: 72.2%\n",
            "Val Error: \n",
            " Accuracy: 69.8%, Avg loss: 0.779382 \n",
            "\n",
            "Epoch 47\n",
            "-------------------------------\n",
            "loss: 0.979329  [    0/20380]\n",
            "Train Error: Accuracy: 69.7%\n",
            "loss: 0.751712  [ 6400/20380]\n",
            "Train Error: Accuracy: 73.0%\n",
            "loss: 0.691022  [12800/20380]\n",
            "Train Error: Accuracy: 72.2%\n",
            "loss: 0.550783  [19200/20380]\n",
            "Train Error: Accuracy: 71.9%\n",
            "epoch over\n",
            "loss: 0.527101  [ 8904/20380]\n",
            "Train Error: Accuracy: 72.5%\n",
            "Val Error: \n",
            " Accuracy: 70.1%, Avg loss: 0.775357 \n",
            "\n",
            "Epoch 48\n",
            "-------------------------------\n",
            "loss: 0.973078  [    0/20380]\n",
            "Train Error: Accuracy: 69.9%\n",
            "loss: 0.745633  [ 6400/20380]\n",
            "Train Error: Accuracy: 73.2%\n",
            "loss: 0.680073  [12800/20380]\n",
            "Train Error: Accuracy: 72.6%\n",
            "loss: 0.542703  [19200/20380]\n",
            "Train Error: Accuracy: 72.2%\n",
            "epoch over\n",
            "loss: 0.517302  [ 8904/20380]\n",
            "Train Error: Accuracy: 72.8%\n",
            "Val Error: \n",
            " Accuracy: 70.0%, Avg loss: 0.772351 \n",
            "\n",
            "Epoch 49\n",
            "-------------------------------\n",
            "loss: 0.969800  [    0/20380]\n",
            "Train Error: Accuracy: 70.2%\n",
            "loss: 0.738816  [ 6400/20380]\n",
            "Train Error: Accuracy: 73.5%\n",
            "loss: 0.667958  [12800/20380]\n",
            "Train Error: Accuracy: 72.9%\n",
            "loss: 0.535508  [19200/20380]\n",
            "Train Error: Accuracy: 72.5%\n",
            "epoch over\n",
            "loss: 0.508113  [ 8904/20380]\n",
            "Train Error: Accuracy: 73.1%\n",
            "Val Error: \n",
            " Accuracy: 70.3%, Avg loss: 0.768872 \n",
            "\n",
            "Epoch 50\n",
            "-------------------------------\n",
            "loss: 0.965089  [    0/20380]\n",
            "Train Error: Accuracy: 70.2%\n",
            "loss: 0.732520  [ 6400/20380]\n",
            "Train Error: Accuracy: 73.8%\n",
            "loss: 0.657010  [12800/20380]\n",
            "Train Error: Accuracy: 73.2%\n",
            "loss: 0.527935  [19200/20380]\n",
            "Train Error: Accuracy: 72.7%\n",
            "epoch over\n",
            "loss: 0.497256  [ 8904/20380]\n",
            "Train Error: Accuracy: 73.3%\n",
            "Val Error: \n",
            " Accuracy: 70.3%, Avg loss: 0.765931 \n",
            "\n",
            "Epoch 51\n",
            "-------------------------------\n",
            "loss: 0.960505  [    0/20380]\n",
            "Train Error: Accuracy: 70.2%\n",
            "loss: 0.727688  [ 6400/20380]\n",
            "Train Error: Accuracy: 74.1%\n",
            "loss: 0.646589  [12800/20380]\n",
            "Train Error: Accuracy: 73.4%\n",
            "loss: 0.519625  [19200/20380]\n",
            "Train Error: Accuracy: 72.9%\n",
            "epoch over\n",
            "loss: 0.487802  [ 8904/20380]\n",
            "Train Error: Accuracy: 73.5%\n",
            "Val Error: \n",
            " Accuracy: 70.2%, Avg loss: 0.763167 \n",
            "\n",
            "Epoch 52\n",
            "-------------------------------\n",
            "loss: 0.955331  [    0/20380]\n",
            "Train Error: Accuracy: 70.4%\n",
            "loss: 0.719652  [ 6400/20380]\n",
            "Train Error: Accuracy: 74.4%\n",
            "loss: 0.633723  [12800/20380]\n",
            "Train Error: Accuracy: 73.6%\n",
            "loss: 0.512538  [19200/20380]\n",
            "Train Error: Accuracy: 73.1%\n",
            "epoch over\n",
            "loss: 0.479093  [ 8904/20380]\n",
            "Train Error: Accuracy: 73.7%\n",
            "Val Error: \n",
            " Accuracy: 70.3%, Avg loss: 0.760936 \n",
            "\n",
            "Validation no longer rising. Done!\n",
            "Max number of epochs hit or validation stop reached. Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,loss_rec)\n",
        "plt.title('Epochs vs Loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "_rhgf1oj9xzG",
        "outputId": "19501b9f-b6ae-409e-f8a2-460994b712e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,acc_rec)\n",
        "plt.title('Epochs vs Accuracy')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CVi8iuEL91LW",
        "outputId": "b3825af4-63c5-4fe0-fd5a-2f040fce9d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcKELHLWEnxd",
        "outputId": "404b71d9-aa77-4a81-96e3-70f38cc73c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 70.2%, Avg loss: 0.753747 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM"
      ],
      "metadata": {
        "id": "mM7rWuUBThcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    #this time we'll let our init take arguments for what the \n",
        "    #input/output size and various other hyperparameters can be\n",
        "    def __init__(self, input_size, hidden_size, layer_size, output_size):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "\n",
        "        #number features hidden\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        #number of hidden layers\n",
        "        self.layer_size = layer_size\n",
        "        self.output_size = output_size\n",
        "        \n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
        "        #note - empty h_0 and c_0 arguments will initialize to 0 if not provided\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, layer_size, batch_first=True)\n",
        "        \n",
        "        self.lstm_filter = nn.Linear(input_size, hidden_size)\n",
        "        self.op = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out, hncn = self.lstm(x)\n",
        "        out = out.view(len(out),-1)\n",
        "        out = self.op(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "GlEaCkccwb_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code snippet attribution:\n",
        "#https://pytorch.org/tutorials/beginner/basics/intro.html\n",
        "#was used as part of the research process\n",
        "#Modifications were made so that data could be processed as longs,\n",
        "#additional statistics could be reported, \n",
        "#and a separate validate process was created. \n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    end = math.floor(size/batch_size)\n",
        "    #print(size)\n",
        "    #print(end)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        #print(X.size())\n",
        "        #print(batch)\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.long()) #loss function requires longs\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        current =  batch * len(X)\n",
        "        #When all batches complete\n",
        "        if batch % 100 == 0:\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            #return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "        if (batch>=end): #on last value of enumerate\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(\"epoch over\")\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "\n",
        "#validation\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return correct\n",
        "\n",
        "#test - only use when training/validation are over\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "1XQuhIw6wb_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll use same loss and SGD as last time\n",
        "input_s = 7 #input features (7 measured values)\n",
        "hidden_s = 256 # hidden features\n",
        "layer_s = 2 # #of hidden layers\n",
        "output_s = 5 #output features - (5 possible actions)\n",
        "\n",
        "model = LSTM(input_s,hidden_s,layer_s,output_s).to(device)\n",
        "print(model)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3139b5ba-dff0-4d26-9d93-2f9c0233d947",
        "id": "ERoHb2N1wb_c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(7, 256, num_layers=2, batch_first=True)\n",
            "  (lstm_filter): Linear(in_features=7, out_features=256, bias=True)\n",
            "  (op): Linear(in_features=256, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measure validation, and stop the NN if learning has stopped\n",
        "#increasing in validation\n",
        "epochs = 100\n",
        "bestval = 0\n",
        "decval = 0\n",
        "\n",
        "loss_rec = [0]\n",
        "acc_rec = [0]\n",
        "epo_rec = [0]\n",
        "#store loss and accuracy every 10 epochs\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    losst, acct = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    #losst = la_tuple[0]\n",
        "    #acct = la_tuple[1]\n",
        "    print(\"val\")\n",
        "    tempval = validate(val_dataloader, model, loss_fn)\n",
        "    #if (t+1) % 10 == 0: #change to desired epoch records factor - e.g. t+1 % 10 every 10 epochs\n",
        "    if 1==1: #test statement\n",
        "      loss_rec.append(losst)\n",
        "      acc_rec.append(acct)\n",
        "      epo_rec.append(t+1)\n",
        "\n",
        "    if(tempval < bestval):\n",
        "      decval+=1 \n",
        "      if(decval==3):\n",
        "        loss_rec.append(losst)\n",
        "        acc_rec.append(acct)\n",
        "        epo_rec.append(t+1)\n",
        "        print(\"Validation no longer rising. Done!\")\n",
        "        break\n",
        "    else:\n",
        "      bestval=tempval\n",
        "print(\"Max number of epochs hit or validation stop reached. Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aaf44ed-a6b5-4311-b861-10ddea4f4922",
        "id": "caYev-HPwb_e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.602212  [    0/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "loss: 1.610298  [ 6400/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "loss: 1.606982  [12800/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "loss: 1.607945  [19200/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "epoch over\n",
            "loss: 1.606727  [ 8904/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 19.7%, Avg loss: 1.608948 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.606284  [    0/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "loss: 1.609784  [ 6400/20380]\n",
            "Train Error: Accuracy: 19.9%\n",
            "loss: 1.606624  [12800/20380]\n",
            "Train Error: Accuracy: 21.5%\n",
            "loss: 1.607972  [19200/20380]\n",
            "Train Error: Accuracy: 23.4%\n",
            "epoch over\n",
            "loss: 1.608136  [ 8904/20380]\n",
            "Train Error: Accuracy: 23.9%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 22.3%, Avg loss: 1.608013 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.607829  [    0/20380]\n",
            "Train Error: Accuracy: 23.8%\n",
            "loss: 1.609398  [ 6400/20380]\n",
            "Train Error: Accuracy: 22.3%\n",
            "loss: 1.606129  [12800/20380]\n",
            "Train Error: Accuracy: 23.4%\n",
            "loss: 1.607464  [19200/20380]\n",
            "Train Error: Accuracy: 23.5%\n",
            "epoch over\n",
            "loss: 1.608451  [ 8904/20380]\n",
            "Train Error: Accuracy: 25.3%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 24.5%, Avg loss: 1.607251 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.608163  [    0/20380]\n",
            "Train Error: Accuracy: 25.7%\n",
            "loss: 1.608936  [ 6400/20380]\n",
            "Train Error: Accuracy: 26.4%\n",
            "loss: 1.605491  [12800/20380]\n",
            "Train Error: Accuracy: 23.9%\n",
            "loss: 1.606666  [19200/20380]\n",
            "Train Error: Accuracy: 25.3%\n",
            "epoch over\n",
            "loss: 1.608283  [ 8904/20380]\n",
            "Train Error: Accuracy: 27.4%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 26.9%, Avg loss: 1.606500 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.607959  [    0/20380]\n",
            "Train Error: Accuracy: 27.8%\n",
            "loss: 1.608417  [ 6400/20380]\n",
            "Train Error: Accuracy: 28.0%\n",
            "loss: 1.604757  [12800/20380]\n",
            "Train Error: Accuracy: 25.4%\n",
            "loss: 1.605702  [19200/20380]\n",
            "Train Error: Accuracy: 27.1%\n",
            "epoch over\n",
            "loss: 1.607896  [ 8904/20380]\n",
            "Train Error: Accuracy: 28.7%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 27.9%, Avg loss: 1.605720 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.607502  [    0/20380]\n",
            "Train Error: Accuracy: 29.0%\n",
            "loss: 1.607856  [ 6400/20380]\n",
            "Train Error: Accuracy: 29.0%\n",
            "loss: 1.603945  [12800/20380]\n",
            "Train Error: Accuracy: 26.9%\n",
            "loss: 1.604621  [19200/20380]\n",
            "Train Error: Accuracy: 28.3%\n",
            "epoch over\n",
            "loss: 1.607392  [ 8904/20380]\n",
            "Train Error: Accuracy: 29.5%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 28.8%, Avg loss: 1.604889 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.606909  [    0/20380]\n",
            "Train Error: Accuracy: 30.0%\n",
            "loss: 1.607252  [ 6400/20380]\n",
            "Train Error: Accuracy: 29.4%\n",
            "loss: 1.603056  [12800/20380]\n",
            "Train Error: Accuracy: 28.2%\n",
            "loss: 1.603434  [19200/20380]\n",
            "Train Error: Accuracy: 29.1%\n",
            "epoch over\n",
            "loss: 1.606809  [ 8904/20380]\n",
            "Train Error: Accuracy: 30.3%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 29.0%, Avg loss: 1.603989 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.606216  [    0/20380]\n",
            "Train Error: Accuracy: 30.6%\n",
            "loss: 1.606600  [ 6400/20380]\n",
            "Train Error: Accuracy: 29.9%\n",
            "loss: 1.602076  [12800/20380]\n",
            "Train Error: Accuracy: 28.9%\n",
            "loss: 1.602136  [19200/20380]\n",
            "Train Error: Accuracy: 29.7%\n",
            "epoch over\n",
            "loss: 1.606154  [ 8904/20380]\n",
            "Train Error: Accuracy: 30.6%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 29.9%, Avg loss: 1.603003 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.605431  [    0/20380]\n",
            "Train Error: Accuracy: 30.9%\n",
            "loss: 1.605889  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.1%\n",
            "loss: 1.600990  [12800/20380]\n",
            "Train Error: Accuracy: 29.3%\n",
            "loss: 1.600708  [19200/20380]\n",
            "Train Error: Accuracy: 30.0%\n",
            "epoch over\n",
            "loss: 1.605419  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.2%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 30.4%, Avg loss: 1.601911 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.604545  [    0/20380]\n",
            "Train Error: Accuracy: 31.3%\n",
            "loss: 1.605107  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.4%\n",
            "loss: 1.599775  [12800/20380]\n",
            "Train Error: Accuracy: 30.1%\n",
            "loss: 1.599130  [19200/20380]\n",
            "Train Error: Accuracy: 30.6%\n",
            "epoch over\n",
            "loss: 1.604591  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.3%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 30.7%, Avg loss: 1.600692 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.603542  [    0/20380]\n",
            "Train Error: Accuracy: 31.4%\n",
            "loss: 1.604240  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.7%\n",
            "loss: 1.598407  [12800/20380]\n",
            "Train Error: Accuracy: 30.5%\n",
            "loss: 1.597375  [19200/20380]\n",
            "Train Error: Accuracy: 31.0%\n",
            "epoch over\n",
            "loss: 1.603655  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.4%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.1%, Avg loss: 1.599321 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.602402  [    0/20380]\n",
            "Train Error: Accuracy: 31.6%\n",
            "loss: 1.603271  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.7%\n",
            "loss: 1.596858  [12800/20380]\n",
            "Train Error: Accuracy: 30.8%\n",
            "loss: 1.595413  [19200/20380]\n",
            "Train Error: Accuracy: 31.1%\n",
            "epoch over\n",
            "loss: 1.602585  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.6%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.1%, Avg loss: 1.597770 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.601103  [    0/20380]\n",
            "Train Error: Accuracy: 31.7%\n",
            "loss: 1.602181  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.7%\n",
            "loss: 1.595096  [12800/20380]\n",
            "Train Error: Accuracy: 30.9%\n",
            "loss: 1.593210  [19200/20380]\n",
            "Train Error: Accuracy: 31.2%\n",
            "epoch over\n",
            "loss: 1.601357  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.7%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.5%, Avg loss: 1.596006 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.599616  [    0/20380]\n",
            "Train Error: Accuracy: 31.9%\n",
            "loss: 1.600949  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.8%\n",
            "loss: 1.593086  [12800/20380]\n",
            "Train Error: Accuracy: 31.2%\n",
            "loss: 1.590731  [19200/20380]\n",
            "Train Error: Accuracy: 31.4%\n",
            "epoch over\n",
            "loss: 1.599940  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.8%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.7%, Avg loss: 1.593995 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.597914  [    0/20380]\n",
            "Train Error: Accuracy: 31.9%\n",
            "loss: 1.599552  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.8%\n",
            "loss: 1.590792  [12800/20380]\n",
            "Train Error: Accuracy: 31.6%\n",
            "loss: 1.587940  [19200/20380]\n",
            "Train Error: Accuracy: 31.6%\n",
            "epoch over\n",
            "loss: 1.598298  [ 8904/20380]\n",
            "Train Error: Accuracy: 32.0%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.9%, Avg loss: 1.591699 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.595969  [    0/20380]\n",
            "Train Error: Accuracy: 32.0%\n",
            "loss: 1.597966  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.8%\n",
            "loss: 1.588176  [12800/20380]\n",
            "Train Error: Accuracy: 31.8%\n",
            "loss: 1.584803  [19200/20380]\n",
            "Train Error: Accuracy: 31.8%\n",
            "epoch over\n",
            "loss: 1.596393  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.8%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.7%, Avg loss: 1.589080 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.593754  [    0/20380]\n",
            "Train Error: Accuracy: 31.8%\n",
            "loss: 1.596166  [ 6400/20380]\n",
            "Train Error: Accuracy: 30.6%\n",
            "loss: 1.585202  [12800/20380]\n",
            "Train Error: Accuracy: 31.7%\n",
            "loss: 1.581290  [19200/20380]\n",
            "Train Error: Accuracy: 31.9%\n",
            "epoch over\n",
            "loss: 1.594183  [ 8904/20380]\n",
            "Train Error: Accuracy: 31.9%\n",
            "val\n",
            "Val Error: \n",
            " Accuracy: 31.5%, Avg loss: 1.586103 \n",
            "\n",
            "Validation no longer rising. Done!\n",
            "Max number of epochs hit or validation stop reached. Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,loss_rec)\n",
        "plt.title('Epochs vs Loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0bf7114e-09d9-48b9-9ff9-5bf6bc009401",
        "id": "jlszQbBlwb_h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdM0lEQVR4nO3df5TddX3n8edrZhJ+hBBIZkRJAqEaT42KqCO21VOh2m6gXbD1F1lqtUVTu0Xt2uOKuy60uNuteqouFbXRIv6oIHWFZtcodhVlt4plOEUkUGwaQRLR3BuQzA3JnczMe/+43zvznZt7Z+6E+c5Nvp/X45w5ud/f7xmGed3P93M/n68iAjMzS1dfrwswM7PechCYmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSXOQWCWIykkPaPXdZgtJgeBHbUkPSjpgKRa7usjva5rsUj6pqQ39boOK7+BXhdgNod/GxH/p9dFmJWZWwR2TJL0Rkn/IOkjkh6X9M+SXp7bfrqkrZIelbRD0ptz2/ol/SdJ/yppVNJdktbmTv8KSf8i6WeSrpWk7LhnSPpWdr2qpC90qO0rki5vWfc9Sb+lhg9J2iNpn6TvS3rOPL/3PknvkfRQdp7PSFqRbTte0uck7c3qv1PSabmf2c7se/6hpEvnc10rLweBHcteDPwrMAhcBXxJ0sps243ALuB04NXAn0n6lWzbO4BNwIXAycDvAU/kzvsbwIuAs4HXAv8mW/9e4GvAqcAa4C871HVDdn4AJG0AzgS+DPwa8MvAM4EV2fn3zvP7fmP2dT7wc8BJQPOW2Ruy864FVgFvAQ5IWgZcA1wQEcuBXwLunud1raQcBHa0uyV7Z9v8enNu2x7gwxFxKCK+ADwA/Hr27v4lwLsi4mBE3A18Evid7Lg3Ae+JiAei4XsRkf9j/OcR8bOI+BFwG3BOtv4QjT/op2fn/X8dar4ZOEfSmdnypcCXIqKenWM58POAIuL+iHhknj+TS4EPRsTOiKgB7wYukTSQnX8V8IyImIiIuyJiX3bcJPAcSSdExCMRsX2e17WSchDY0e6VEXFK7usTuW27Y+asiQ/RaAGcDjwaEaMt21Znr9fSaEl08pPc6ydovOMG+I+AgH+UtF3S77U7OLvul4FLslWbgL/Jtn2Dxrv3a4E9krZIOnmWWto5Pft+mh6i0d93GvBZ4FbgRkk/lvR+SUsiYj/wOhothEckfVnSz8/zulZSDgI7lq1u3r/PnAH8OPtaKWl5y7bd2euHgafP92IR8ZOIeHNEnA78PvDRWT5qegOwSdIvAsfTaFk0z3NNRLwQ2EDjFtE751nKj2m0TJrOAMaBn2atoz+NiA00bv/8BllLKCJujYhfBZ4G/DPwCcxwENix7SnA2yQtkfQa4FnAtoh4GPg28N+zztOzgcuAz2XHfRJ4r6T1Weft2ZJWzXUxSa+RtCZbfAwIGrdb2tlG44/11cAXImIyO8eLJL1Y0hJgP3BwlnMADGTfQ/NrCY2Q+Q+SzpJ0EvBn2TXGJZ0v6bmS+oF9NG4VTUo6TdLFWV9BHajNcV1LiIPAjnb/q2Ucwc25bd8F1gNV4L8Br87d698ErKPx7vlm4Krcx1A/CNxEo+N3H/DXwAld1PIi4LuSasBW4O0RsbPdjll/wJeAVwCfz206mcY78cdo3NLZC3xglmt+DDiQ+/oUcB2NW0C3Az+kESZvzfZ/KvDF7Pu6H/hWtm8fjU7yHwOPAi8D/qCL79kSID+Yxo5Fkt4IvCkiXtrrWsyOdW4RmJklzkFgZpY43xoyM0ucWwRmZok75iadGxwcjHXr1vW6DDOzY8pdd91VjYihdtuOuSBYt24dIyMjvS7DzOyYIumhTtt8a8jMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxBUWBJKuy56neu8s+5wn6e7sIR/fKqoWMzPrrMhxBNfTeBLTZ9ptlHQK8FFgY0T8SNJTCqxlwRw8NMF3f/go9UMTTAZMRjAZwcRkEAETkzG1bjJbjmz7zP0br5uaU300V8XUegjab6PT9CC5Z7Wo/WqU2zJz/fRy/pkvUuOYqW35/XLr88dp6rjGuuZrNH31/HmVWyZ/XHN9aw35bS3nYMZyyzmmlqfX9zVrajlXX59mnLNPhx9H/hy54/tydfS1OSZ/7r58TbnlvqyQ1nXquC7/X9ysO4UFQUTcLmndLLv8OxrPcf1Rtv+eompZSH971y7+yy0dGzmLrvX/e08dZc2wyodWXz5gciHX12a/qeP7msuHh1NzublP83p9M/6dub1fbfbNXWN63eGv+5vnaG7Lau/P1dt2W1/juv19zdf5fxvX6G9ZP3PfxrUH+jW9b9/0Mc3Xfdk+zfMM9OX+VePf/j4dtUHdy5HFzwSWSPomjYd5/4+I6NR62AxsBjjjjDMWrcB2dj92gCX94uZ//5KpX+TDfknzv2wtv5jK9s+/q4PD323D4e+s8+vmK2a0PnLrW/ZpbYnM2HeqRRIzWidTrZn8uXPHR+7c+RYOwYx1M/aN6Wt2Og8z1uf2a6m93Tkm2xw/GTFdX+v6GdfOX2f6OGicN3+9Zqtv5vmz9TPO3XKd3P6HnSN3zeb30nr89LHTdU9OHn7sROt+U63W6fNMttTSeu7JCCZyxzdbxROTwaGJmdsnI5icnD7fxIzzTbesm6+7bXUfK/IBMtAn+vunQ2Kgr4++Phjo65venvu3v0+88vmrufTFZ859oXnqZRAMAC8EXk7j6VDfkXRHRPygdceI2AJsARgeHu7pf/Vqrc6qZcfxnNUrelnGvLXe5umw16LUYrbQIhcK+eCYnGyETT6cpgKlzfrJGes4bPvEZEwd19w2PtFYNzkZjOfWNY8bn5zeNtGyz8Tk5Iz1+euMT07OWD8+ETNu6S6kXgbBLmBvROwH9ku6HXgecFgQHE2qtTpDy4/rdRlmltO89dTf5zczR6KXHx/9O+ClkgYknQi8mMYzVo9q1VqdwZOW9roMM7MFU1iLQNINwHnAoKRdwFXAEoCI+HhE3C/pq8A9wCTwyYg4enphO6iM1nnWU0/udRlmZgumyE8Nbepinw8AHyiqhoU2ORnsrY0x6FtDZlYiHlk8D48fOMT4ZDB4koPAzMrDQTAP1VodwJ3FZlYqDoJ5qGRB4M5iMysTB8E8VEazFoFvDZlZiTgI5qFaGwNwH4GZlYqDYB6qtToDfWLFCUt6XYqZ2YJxEMxDdbTO4EnH0efRi2ZWIg6CeajW6gwud0exmZWLg2AeKrW6+wfMrHQcBPNQHR1zEJhZ6TgIuhQR7N3vFoGZlY+DoEuPHzjEoYnwqGIzKx0HQZeqHlVsZiXlIOjSHo8qNrOSchB0aWpUsW8NmVnJOAi6VHWLwMxKqrAgkHSdpD2SZn3qmKQXSRqX9OqialkInl7CzMqqyBbB9cDG2XaQ1A+8D/hagXUsiMponVUnLfX0EmZWOoUFQUTcDjw6x25vBf4nsKeoOhZK1aOKzayketZHIGk18JvAx7rYd7OkEUkjlUql+OLaqNY8qtjMyqmXncUfBt4VEZNz7RgRWyJiOCKGh4aGFqG0w1VrdQ8mM7NSGujhtYeBGyUBDAIXShqPiFt6WFNbEeFbQ2ZWWj0Lgog4q/la0vXA/z4aQwCmp5fwqGIzK6PCgkDSDcB5wKCkXcBVwBKAiPh4UdctQnN6Cd8aMrMyKiwIImLTPPZ9Y1F1LITKqJ9VbGbl5ZHFXXCLwMzKzEHQhemZRx0EZlY+DoIuVEbr9PeJUzy9hJmVkIOgC9VanVXLPL2EmZWTg6ALHlVsZmXmIOiCRxWbWZk5CLpQHfWoYjMrLwfBHBrTS4wxuNyjis2snBwEc9h3YJyxiUk/mczMSstBMIeKB5OZWck5CObgwWRmVnYOgjk4CMys7BwEc6iMNoPAncVmVk4OgjlUa43pJU490UFgZuXkIJhDdXTM00uYWakVFgSSrpO0R9K9HbZfKukeSd+X9G1JzyuqlifDj6g0s7IrskVwPbBxlu0/BF4WEc8F3gtsKbCWI1ap1Rn0R0fNrMQKC4KIuB14dJbt346Ix7LFO4A1RdXyZDSml3D/gJmV19HSR3AZ8JVOGyVtljQiaaRSqSxaUc3pJTyq2MzKrOdBIOl8GkHwrk77RMSWiBiOiOGhoaFFq23fwWx6Cd8aMrMSK+zh9d2QdDbwSeCCiNjby1ra8WAyM0tBz1oEks4AvgS8PiJ+0Ks6ZjM9mMxBYGblVViLQNINwHnAoKRdwFXAEoCI+DhwJbAK+KgkgPGIGC6qniMx1SLwFNRmVmKFBUFEbJpj+5uANxV1/YVQzVoE7iw2szLreWfx0axaG/P0EmZWeg6CWVRrdVZ6egkzKzkHwSwqflaxmSXAQTCLxjxDvi1kZuXmIJhFtTbmwWRmVnoOgg4igkqt7k8MmVnpOQg6GK2PMzY+6T4CMys9B0EHU6OKPZjMzErOQdBB1dNLmFkiHAQdVGtjAO4sNrPScxB04JlHzSwVDoIOqrU6fcLTS5hZ6TkIOqiM1lm57Dj6Pb2EmZWcg6ADjyo2s1Q4CDqoeFSxmSXCQdBBddSjis0sDYUFgaTrJO2RdG+H7ZJ0jaQdku6R9IKiapmv5vQSg24RmFkCimwRXA9snGX7BcD67Gsz8LECa5mX6ekl3EdgZuVXWBBExO3Ao7PscjHwmWi4AzhF0tOKqmc+ph5R6RaBmSWgl30Eq4GHc8u7snWHkbRZ0oikkUqlUnhhzVHFHkxmZik4JjqLI2JLRAxHxPDQ0FDh1/OoYjNLSS+DYDewNre8JlvXcxVPOGdmCellEGwFfif79NAvAI9HxCM9rGdKc3qJlcvcWWxm5TdQ1Ikl3QCcBwxK2gVcBSwBiIiPA9uAC4EdwBPA7xZVy3xVa55ewszSUVgQRMSmObYH8IdFXf/JqIyO+aOjZpaMY6KzeLFVa3V/dNTMkuEgaKMyWndHsZklw0HQIiI886iZJcVB0KJWH6c+PulbQ2aWDAdBC48qNrPUOAhaeFSxmaXGQdDCo4rNLDUOghZTLYLl7iw2szQ4CFpURxvTS6xa5haBmaXBQdCiUhtj5bKlnl7CzJLRVRBIWiapL3v9TEkXSVpSbGm90RhD4NaAmaWj2xbB7cDxklYDXwNeT+NRlKXjUcVmlppug0AR8QTwW8BHI+I1wLOLK6t3PM+QmaWm6yCQ9IvApcCXs3X9xZTUO55ewsxS1G0Q/BHwbuDmiNgu6eeA24orqzf2j01w8NCkbw2ZWVK6CoKI+FZEXBQR78s6jasR8ba5jpO0UdIDknZIuqLN9jMk3SbpnyTdI+nCI/geFkzVg8nMLEHdfmro85JOlrQMuBe4T9I75zimH7gWuADYAGyStKFlt/cAN0XE84FLgI/O9xtYSJWpwWQOAjNLR7e3hjZExD7glcBXgLNofHJoNucCOyJiZ0SMATcCF7fsE8DJ2esVwI+7rKcQzRbBkFsEZpaQboNgSTZu4JXA1og4ROOP+GxWAw/nlndl6/L+BPjt7JnG24C3dllPITy9hJmlqNsg+CvgQWAZcLukM4F9C3D9TcD1EbGGxoPsP9scuJYnabOkEUkjlUplAS7bXqU2hgQrT3QQmFk6uu0sviYiVkfEhdHwEHD+HIftBtbmltdk6/IuA27KrvEd4HhgsM31t0TEcEQMDw0NdVPyEamM1ll54lIG+j3zhpmlo9vO4hWSPth8Vy7pL2i0DmZzJ7Be0lmSltLoDN7ass+PgJdn13gWjSAo7i3/HDy9hJmlqNu3vtcBo8Brs699wKdmOyAixoHLgVuB+2l8Omi7pKslXZTt9sfAmyV9D7gBeGNEzNX3UBiPKjazFA10ud/TI+JVueU/lXT3XAdFxDYancD5dVfmXt8HvKTLGgpXrdU584wTe12Gmdmi6rZFcEDSS5sLkl4CHCimpN6ICKqjY741ZGbJ6bZF8BbgM5JWZMuPAW8opqTe2D82wYFDEx5MZmbJ6SoIIuJ7wPMknZwt75P0R8A9RRa3mDyYzMxSNa/PSUbEvmyEMcA7CqinZ6qeXsLMEvVkPjBfqmc5TgWBp6A2s8Q8mSDo2cc8i1CpjQG+NWRm6Zm1j0DSKO3/4As4oZCKeqQyWm9ML7HMLQIzS8usQRARyxerkF6r1jy9hJmlyX/1MlU/tN7MEuUgyFRrdU8/bWZJchBkqjWPKjazNDkIMhXfGjKzRDkIgP31cQ4cmvDMo2aWJAcB+cFkDgIzS4+DAI8qNrO0OQiAymhjVLFbBGaWokKDQNJGSQ9I2iHpig77vFbSfZK2S/p8kfV0UslaBO4jMLMUdfs8gnmT1A9cC/wqsAu4U9LW7KlkzX3WA+8GXhIRj0l6SlH1zKbq6SXMLGFFtgjOBXZExM6IGANuBC5u2efNwLUR8RhAROwpsJ6OqrU6p564lCWeXsLMElTkX77VwMO55V3ZurxnAs+U9A+S7pC0sd2JJG2WNCJppFKpLHih1VrdHcVmlqxevwUeANYD5wGbgE9IOqV1p4jYEhHDETE8NDS04EV4MJmZpazIINgNrM0tr8nW5e0CtkbEoYj4IfADGsGwqKq1MXcUm1myigyCO4H1ks6StBS4BNjass8tNFoDSBqkcatoZ4E1tdW4NeQgMLM0FRYEETEOXA7cCtwP3BQR2yVdLemibLdbgb2S7gNuA94ZEXuLqqmdJ8bGeWJswkFgZskq7OOjABGxDdjWsu7K3OsA3pF99UR1ajCZO4vNLE297izuuUrtIACD7iMws0Q5CEb90HozS1vyQVD19BJmljgHQRYEnl7CzFLlIKjVOfXEJZ5ewsySlfxfP48qNrPUJR8EHlVsZqlzEHhUsZklzkHgW0Nmlrikg+CJsXH2j00wuNyfGDKzdCUdBFU/q9jMLO0g8LOKzcwSD4KpUcVuEZhZwhwE+NaQmaUt7SDI+ghWeQpqM0tY0kFQqR309BJmlrxC/wJK2ijpAUk7JF0xy36vkhSShousp1V1dMy3hcwseYUFgaR+4FrgAmADsEnShjb7LQfeDny3qFo68ahiM7NiWwTnAjsiYmdEjAE3Ahe32e+9wPuAgwXW0la1VveTycwseUUGwWrg4dzyrmzdFEkvANZGxJdnO5GkzZJGJI1UKpUFK7Ax86g7is0sbT3rJZXUB3wQ+OO59o2ILRExHBHDQ0NDC3L9A2MT7B+b8GAyM0tekUGwG1ibW16TrWtaDjwH+KakB4FfALYuVoexxxCYmTUUGQR3AuslnSVpKXAJsLW5MSIej4jBiFgXEeuAO4CLImKkwJqmVDyq2MwMKDAIImIcuBy4FbgfuCkitku6WtJFRV23W9VRtwjMzAAGijx5RGwDtrWsu7LDvucVWUurZovAU1CbWeqSHVI7Nb3EMrcIzCxt6QZBrc4pJy5h6UCyPwIzMyDxIHD/gJlZ8kHg/gEzs2SDoDJaZ2j58b0uw8ys55INgmptzC0CMzMSDYKDhyao1cfdR2BmRqJBUBn1qGIzs6Ykg6DqwWRmZlOSDILpFoE7i83MkgyCaq0xqtgtAjOzZIOg0SLw9BJmZgkHwYoTPL2EmRkkHAQeQ2Bm1pBkEDRGFfu2kJkZFBwEkjZKekDSDklXtNn+Dkn3SbpH0tclnVlkPU2NUcUOAjMzKDAIJPUD1wIXABuATZI2tOz2T8BwRJwNfBF4f1H15FVHPfOomVlTkS2Cc4EdEbEzIsaAG4GL8ztExG0R8US2eAeNB9wX6uChCUbr4741ZGaWKTIIVgMP55Z3Zes6uQz4SrsNkjZLGpE0UqlUnlRRlalnFbuz2MwMjpLOYkm/DQwDH2i3PSK2RMRwRAwPDQ09qWs1xxC4RWBm1lDkw+t3A2tzy2uydTNIegXwn4GXRUS9wHqA3Khi9xGYmQHFtgjuBNZLOkvSUuASYGt+B0nPB/4KuCgi9hRYy5SpCeccBGZmQIFBEBHjwOXArcD9wE0RsV3S1ZIuynb7AHAS8LeS7pa0tcPpFkw16yNY5T4CMzOg2FtDRMQ2YFvLuitzr19R5PXbqWTTSxw30L/YlzYzOyodFZ3Fi8nTS5iZzZReEIx6VLGZWV56QVCrM+iPjpqZTUkuCCq1up9VbGaWk1QQHDw0wehBTy9hZpaXVBBMjyFwZ7GZWVNiQeBRxWZmrdIKglGPKjYza5VWEDRvDbmPwMxsSlJB4CmozcwOl1QQVGt1Tj5+wNNLmJnlJBYEY74tZGbWIqkgqNT8rGIzs1ZJBUHVo4rNzA6TVBBURuseVWxm1iKZIGhOL+FPDJmZzVRoEEjaKOkBSTskXdFm+3GSvpBt/66kdUXVsne/RxWbmbVTWBBI6geuBS4ANgCbJG1o2e0y4LGIeAbwIeB9RdXjUcVmZu0V2SI4F9gRETsjYgy4Ebi4ZZ+LgU9nr78IvFySiiimOZjMfQRmZjMVGQSrgYdzy7uydW33yR52/ziwqvVEkjZLGpE0UqlUjqiYU5ctYeOzn8rTTjn+iI43MyurQh9ev1AiYguwBWB4eDiO5BwvPHMlL3z9ygWty8ysDIpsEewG1uaW12Tr2u4jaQBYAewtsCYzM2tRZBDcCayXdJakpcAlwNaWfbYCb8hevxr4RkQc0Tt+MzM7MoXdGoqIcUmXA7cC/cB1EbFd0tXASERsBf4a+KykHcCjNMLCzMwWUaF9BBGxDdjWsu7K3OuDwGuKrMHMzGaXzMhiMzNrz0FgZpY4B4GZWeIcBGZmidOx9mlNSRXgoSM8fBCoLmA51p5/zsXzz3hxlOnnfGZEDLXbcMwFwZMhaSQihntdR9n551w8/4wXRyo/Z98aMjNLnIPAzCxxqQXBll4XkAj/nIvnn/HiSOLnnFQfgZmZHS61FoGZmbVwEJiZJS6ZIJC0UdIDknZIuqLX9ZSVpAclfV/S3ZJGel1PGUi6TtIeSffm1q2U9PeS/iX799Re1lgGHX7OfyJpd/b7fLekC3tZY1GSCAJJ/cC1wAXABmCTpA29rarUzo+Ic1L4/PUiuR7Y2LLuCuDrEbEe+Hq2bE/O9Rz+cwb4UPb7fE42o3LpJBEEwLnAjojYGRFjwI3AxT2uyawrEXE7jed15F0MfDp7/WnglYtaVAl1+DknIZUgWA08nFvela2zhRfA1yTdJWlzr4spsdMi4pHs9U+A03pZTMldLume7NZRKW/BpRIEtnheGhEvoHEb7g8l/XKvCyq77PGu/hx4MT4GPB04B3gE+IvellOMVIJgN7A2t7wmW2cLLCJ2Z//uAW6mcVvOFt5PJT0NIPt3T4/rKaWI+GlETETEJPAJSvr7nEoQ3Amsl3SWpKU0no28tcc1lY6kZZKWN18DvwbcO/tRdoS2Am/IXr8B+Lse1lJazbDN/CYl/X0u9JnFR4uIGJd0OXAr0A9cFxHbe1xWGZ0G3CwJGr9bn4+Ir/a2pGOfpBuA84BBSbuAq4A/B26SdBmNadlf27sKy6HDz/k8SefQuPX2IPD7PSuwQJ5iwswscancGjIzsw4cBGZmiXMQmJklzkFgZpY4B4GZWeIcBGYZSRO5WSbvXshZaiWty89qaXY0SWIcgVmXDkTEOb0uwmyxuUVgNofsGQvvz56z8I+SnpGtXyfpG9mEZF+XdEa2/jRJN0v6Xvb1S9mp+iV9QtJ2SV+TdEK2/9sk3Zed58YefZuWMAeB2bQTWm4NvS637fGIeC7wEeDD2bq/BD4dEWcDfwNck62/BvhWRDwPeAHQHMW+Hrg2Ip4N/Ax4Vbb+CuD52XneUtQ3Z9aJRxabZSTVIuKkNusfBH4lInZKWgL8JCJWSaoCT4uIQ9n6RyJiUFIFWBMR9dw51gF/nz1IBknvApZExH+V9FWgBtwC3BIRtYK/VbMZ3CIw6050eD0f9dzrCab76H6dxhP0XgDcKcl9d7aoHARm3Xld7t/vZK+/TWMmW4BLgf+bvf468AfQeEyqpBWdTiqpD1gbEbcB7wJWAIe1SsyK5HceZtNOkHR3bvmrEdH8COmpku6h8a5+U7burcCnJL0TqAC/m61/O7Almxl0gkYoPEJ7/cDnsrAQcE1E/GzBviOzLriPwGwOWR/BcERUe12LWRF8a8jMLHFuEZiZJc4tAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxP1//74cmmQKG5IAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,acc_rec)\n",
        "plt.title('Epochs vs Accuracy')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0bb3b827-106b-4de2-e367-12d94a2d7df7",
        "id": "C6xhqSpwwb_h"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b848831-5164-4c62-9510-3c1c74958a04",
        "id": "Vyk4oRn1wb_i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 32.9%, Avg loss: 1.585926 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#GRU"
      ],
      "metadata": {
        "id": "w9h-HO5mTiwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRU(nn.Module):\n",
        "    #this time we'll let our init take arguments for what the \n",
        "    #input/output size and various other hyperparameters can be\n",
        "    def __init__(self, input_size, hidden_size, layer_size, output_size):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "\n",
        "        #number features hidden\n",
        "        self.hidden_size = hidden_size\n",
        "        #number of hidden layers\n",
        "        self.layer_size = layer_size\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.GRU.html\n",
        "        self.gru = nn.GRU(input_size, hidden_size, layer_size, batch_first=True)\n",
        "        #We need a final output layer \n",
        "        self.op = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        #print(x.size())\n",
        "        # Initialize hidden state with zeros\n",
        "        #h0 = Variable(torch.zeros(self.layer_size, x.size(0), self.hidden_size))\n",
        "        h0 = Variable(torch.zeros(self.layer_size, self.hidden_size))\n",
        "            \n",
        "        # One time step on RNN\n",
        "        out, hn = self.gru(x, h0)\n",
        "        #seq, batch, feature\n",
        "        out = self.op(out) \n",
        "        #out = self.fc(out[:, -1, :]) \n",
        "        return out"
      ],
      "metadata": {
        "id": "72-VuIDuRUa8"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Code snippet attribution:\n",
        "#https://pytorch.org/tutorials/beginner/basics/intro.html\n",
        "#was used as part of the research process\n",
        "#Modifications were made so that data could be processed as longs,\n",
        "#additional statistics could be reported, \n",
        "#and a separate validate process was created. \n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    end = math.floor(size/batch_size)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y.long()) #loss function requires longs\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        current =  batch * len(X)\n",
        "        #When all batches complete\n",
        "        if batch % 100 == 0:\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            #return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "        if (batch>=end): #on last value of enumerate\n",
        "            #calculate loss, \"correctness\" (accuracy)\n",
        "            #loss, current = loss.item(), batch * len(X)\n",
        "            loss = loss.item()\n",
        "            print(\"epoch over\")\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for X, y in dataloader:\n",
        "                    X, y = X.to(device), y.to(device)\n",
        "                    pred = model(X)\n",
        "                    correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            correct /= size\n",
        "            print(f\"Train Error: Accuracy: {(100*correct):>0.1f}%\")\n",
        "            return (loss, correct) #\"correct\" corresponds to accuracy\n",
        "\n",
        "#validation\n",
        "def validate(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Val Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return correct\n",
        "\n",
        "#test - only use when training/validation are over\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y.long()).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "c7g_rRr8RUa-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll use same loss and SGD as last time\n",
        "input_s = 7 #input features (7 measured values)\n",
        "hidden_s = 265 # hidden features\n",
        "layer_s = 2 # #of hidden layers\n",
        "output_s = 5 #output features - (5 possible actions)\n",
        "\n",
        "model = GRU(input_s,hidden_s,layer_s,output_s).to(device)\n",
        "print(model)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f32acb13-4650-46ae-a930-55a554703171",
        "id": "tQqTiIQeRUbB"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRU(\n",
            "  (gru): GRU(7, 265, num_layers=2, batch_first=True)\n",
            "  (op): Linear(in_features=265, out_features=5, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Measure validation, and stop the NN if learning has stopped\n",
        "#increasing in validation\n",
        "epochs = 100\n",
        "bestval = 0\n",
        "decval = 0\n",
        "\n",
        "loss_rec = [0]\n",
        "acc_rec = [0]\n",
        "epo_rec = [0]\n",
        "#store loss and accuracy every 10 epochs\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    losst, acct = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    tempval = validate(val_dataloader, model, loss_fn)\n",
        "    #if 1==1: #test statement\n",
        "    if (t+1) % 10 == 0: #change to desired epoch records factor - e.g. t+1 % 10 every 10 epochs\n",
        "      loss_rec.append(losst)\n",
        "      acc_rec.append(acct)\n",
        "      epo_rec.append(t+1)\n",
        "\n",
        "    if(tempval < bestval):\n",
        "      decval+=1 \n",
        "      if(decval==3):\n",
        "        loss_rec.append(losst)\n",
        "        acc_rec.append(acct)\n",
        "        epo_rec.append(t+1)\n",
        "        print(\"Validation no longer rising. Done!\")\n",
        "        break\n",
        "    else:\n",
        "      bestval=tempval\n",
        "print(\"Max number of epochs hit or validation stop reached. Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d010dee-b58a-46e9-aed5-96d6d7e4dfc3",
        "id": "kC42WtCeRUbD"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.607778  [    0/20380]\n",
            "Train Error: Accuracy: 23.7%\n",
            "loss: 1.605207  [ 6400/20380]\n",
            "Train Error: Accuracy: 23.8%\n",
            "loss: 1.605819  [12800/20380]\n",
            "Train Error: Accuracy: 27.6%\n",
            "loss: 1.595570  [19200/20380]\n",
            "Train Error: Accuracy: 31.1%\n",
            "epoch over\n",
            "loss: 1.610774  [ 8904/20380]\n",
            "Train Error: Accuracy: 32.1%\n",
            "Val Error: \n",
            " Accuracy: 31.3%, Avg loss: 1.598538 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.602427  [    0/20380]\n",
            "Train Error: Accuracy: 32.1%\n",
            "loss: 1.596616  [ 6400/20380]\n",
            "Train Error: Accuracy: 31.4%\n",
            "loss: 1.599729  [12800/20380]\n",
            "Train Error: Accuracy: 32.2%\n",
            "loss: 1.578959  [19200/20380]\n",
            "Train Error: Accuracy: 32.8%\n",
            "epoch over\n",
            "loss: 1.606571  [ 8904/20380]\n",
            "Train Error: Accuracy: 32.9%\n",
            "Val Error: \n",
            " Accuracy: 33.0%, Avg loss: 1.587878 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.595871  [    0/20380]\n",
            "Train Error: Accuracy: 32.8%\n",
            "loss: 1.586779  [ 6400/20380]\n",
            "Train Error: Accuracy: 32.2%\n",
            "loss: 1.592271  [12800/20380]\n",
            "Train Error: Accuracy: 32.9%\n",
            "loss: 1.559149  [19200/20380]\n",
            "Train Error: Accuracy: 32.9%\n",
            "epoch over\n",
            "loss: 1.601270  [ 8904/20380]\n",
            "Train Error: Accuracy: 33.0%\n",
            "Val Error: \n",
            " Accuracy: 33.2%, Avg loss: 1.575088 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.588302  [    0/20380]\n",
            "Train Error: Accuracy: 32.9%\n",
            "loss: 1.575234  [ 6400/20380]\n",
            "Train Error: Accuracy: 32.2%\n",
            "loss: 1.582812  [12800/20380]\n",
            "Train Error: Accuracy: 33.0%\n",
            "loss: 1.535359  [19200/20380]\n",
            "Train Error: Accuracy: 33.1%\n",
            "epoch over\n",
            "loss: 1.595147  [ 8904/20380]\n",
            "Train Error: Accuracy: 32.8%\n",
            "Val Error: \n",
            " Accuracy: 33.1%, Avg loss: 1.559786 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.580217  [    0/20380]\n",
            "Train Error: Accuracy: 32.8%\n",
            "loss: 1.561898  [ 6400/20380]\n",
            "Train Error: Accuracy: 32.3%\n",
            "loss: 1.571386  [12800/20380]\n",
            "Train Error: Accuracy: 33.2%\n",
            "loss: 1.509253  [19200/20380]\n",
            "Train Error: Accuracy: 33.2%\n",
            "epoch over\n",
            "loss: 1.588999  [ 8904/20380]\n",
            "Train Error: Accuracy: 33.0%\n",
            "Val Error: \n",
            " Accuracy: 33.2%, Avg loss: 1.542964 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.572576  [    0/20380]\n",
            "Train Error: Accuracy: 32.9%\n",
            "loss: 1.547270  [ 6400/20380]\n",
            "Train Error: Accuracy: 32.8%\n",
            "loss: 1.558855  [12800/20380]\n",
            "Train Error: Accuracy: 33.5%\n",
            "loss: 1.483856  [19200/20380]\n",
            "Train Error: Accuracy: 33.7%\n",
            "epoch over\n",
            "loss: 1.583184  [ 8904/20380]\n",
            "Train Error: Accuracy: 33.6%\n",
            "Val Error: \n",
            " Accuracy: 33.3%, Avg loss: 1.526076 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.565330  [    0/20380]\n",
            "Train Error: Accuracy: 33.5%\n",
            "loss: 1.531673  [ 6400/20380]\n",
            "Train Error: Accuracy: 33.4%\n",
            "loss: 1.546039  [12800/20380]\n",
            "Train Error: Accuracy: 34.0%\n",
            "loss: 1.460580  [19200/20380]\n",
            "Train Error: Accuracy: 34.3%\n",
            "epoch over\n",
            "loss: 1.576656  [ 8904/20380]\n",
            "Train Error: Accuracy: 34.2%\n",
            "Val Error: \n",
            " Accuracy: 34.0%, Avg loss: 1.509468 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.556764  [    0/20380]\n",
            "Train Error: Accuracy: 34.2%\n",
            "loss: 1.514768  [ 6400/20380]\n",
            "Train Error: Accuracy: 34.2%\n",
            "loss: 1.533091  [12800/20380]\n",
            "Train Error: Accuracy: 34.7%\n",
            "loss: 1.438864  [19200/20380]\n",
            "Train Error: Accuracy: 35.1%\n",
            "epoch over\n",
            "loss: 1.567777  [ 8904/20380]\n",
            "Train Error: Accuracy: 35.0%\n",
            "Val Error: \n",
            " Accuracy: 34.9%, Avg loss: 1.492616 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.545266  [    0/20380]\n",
            "Train Error: Accuracy: 34.9%\n",
            "loss: 1.496155  [ 6400/20380]\n",
            "Train Error: Accuracy: 35.0%\n",
            "loss: 1.519967  [12800/20380]\n",
            "Train Error: Accuracy: 35.7%\n",
            "loss: 1.417911  [19200/20380]\n",
            "Train Error: Accuracy: 35.8%\n",
            "epoch over\n",
            "loss: 1.555307  [ 8904/20380]\n",
            "Train Error: Accuracy: 35.8%\n",
            "Val Error: \n",
            " Accuracy: 36.1%, Avg loss: 1.475082 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.530359  [    0/20380]\n",
            "Train Error: Accuracy: 35.8%\n",
            "loss: 1.475819  [ 6400/20380]\n",
            "Train Error: Accuracy: 36.1%\n",
            "loss: 1.506857  [12800/20380]\n",
            "Train Error: Accuracy: 36.4%\n",
            "loss: 1.397439  [19200/20380]\n",
            "Train Error: Accuracy: 36.7%\n",
            "epoch over\n",
            "loss: 1.538565  [ 8904/20380]\n",
            "Train Error: Accuracy: 36.8%\n",
            "Val Error: \n",
            " Accuracy: 36.7%, Avg loss: 1.456795 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 1.512302  [    0/20380]\n",
            "Train Error: Accuracy: 36.8%\n",
            "loss: 1.454124  [ 6400/20380]\n",
            "Train Error: Accuracy: 36.8%\n",
            "loss: 1.494219  [12800/20380]\n",
            "Train Error: Accuracy: 37.1%\n",
            "loss: 1.377579  [19200/20380]\n",
            "Train Error: Accuracy: 37.4%\n",
            "epoch over\n",
            "loss: 1.517454  [ 8904/20380]\n",
            "Train Error: Accuracy: 37.4%\n",
            "Val Error: \n",
            " Accuracy: 37.9%, Avg loss: 1.438007 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 1.491723  [    0/20380]\n",
            "Train Error: Accuracy: 37.4%\n",
            "loss: 1.431756  [ 6400/20380]\n",
            "Train Error: Accuracy: 37.6%\n",
            "loss: 1.482671  [12800/20380]\n",
            "Train Error: Accuracy: 38.0%\n",
            "loss: 1.358657  [19200/20380]\n",
            "Train Error: Accuracy: 38.2%\n",
            "epoch over\n",
            "loss: 1.492613  [ 8904/20380]\n",
            "Train Error: Accuracy: 38.2%\n",
            "Val Error: \n",
            " Accuracy: 38.8%, Avg loss: 1.419217 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 1.469554  [    0/20380]\n",
            "Train Error: Accuracy: 38.2%\n",
            "loss: 1.409680  [ 6400/20380]\n",
            "Train Error: Accuracy: 38.2%\n",
            "loss: 1.472824  [12800/20380]\n",
            "Train Error: Accuracy: 38.8%\n",
            "loss: 1.341021  [19200/20380]\n",
            "Train Error: Accuracy: 39.0%\n",
            "epoch over\n",
            "loss: 1.465406  [ 8904/20380]\n",
            "Train Error: Accuracy: 38.9%\n",
            "Val Error: \n",
            " Accuracy: 39.4%, Avg loss: 1.401039 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 1.446934  [    0/20380]\n",
            "Train Error: Accuracy: 38.9%\n",
            "loss: 1.388958  [ 6400/20380]\n",
            "Train Error: Accuracy: 39.0%\n",
            "loss: 1.465070  [12800/20380]\n",
            "Train Error: Accuracy: 39.5%\n",
            "loss: 1.324862  [19200/20380]\n",
            "Train Error: Accuracy: 39.8%\n",
            "epoch over\n",
            "loss: 1.437552  [ 8904/20380]\n",
            "Train Error: Accuracy: 39.8%\n",
            "Val Error: \n",
            " Accuracy: 39.6%, Avg loss: 1.384008 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 1.424922  [    0/20380]\n",
            "Train Error: Accuracy: 39.8%\n",
            "loss: 1.370446  [ 6400/20380]\n",
            "Train Error: Accuracy: 39.7%\n",
            "loss: 1.459430  [12800/20380]\n",
            "Train Error: Accuracy: 40.2%\n",
            "loss: 1.310137  [19200/20380]\n",
            "Train Error: Accuracy: 40.4%\n",
            "epoch over\n",
            "loss: 1.410603  [ 8904/20380]\n",
            "Train Error: Accuracy: 40.3%\n",
            "Val Error: \n",
            " Accuracy: 40.4%, Avg loss: 1.368439 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 1.404222  [    0/20380]\n",
            "Train Error: Accuracy: 40.3%\n",
            "loss: 1.354562  [ 6400/20380]\n",
            "Train Error: Accuracy: 40.2%\n",
            "loss: 1.455563  [12800/20380]\n",
            "Train Error: Accuracy: 40.7%\n",
            "loss: 1.296621  [19200/20380]\n",
            "Train Error: Accuracy: 40.9%\n",
            "epoch over\n",
            "loss: 1.385613  [ 8904/20380]\n",
            "Train Error: Accuracy: 40.8%\n",
            "Val Error: \n",
            " Accuracy: 40.9%, Avg loss: 1.354416 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 1.385121  [    0/20380]\n",
            "Train Error: Accuracy: 40.8%\n",
            "loss: 1.341264  [ 6400/20380]\n",
            "Train Error: Accuracy: 40.8%\n",
            "loss: 1.452927  [12800/20380]\n",
            "Train Error: Accuracy: 41.1%\n",
            "loss: 1.284040  [19200/20380]\n",
            "Train Error: Accuracy: 41.4%\n",
            "epoch over\n",
            "loss: 1.363120  [ 8904/20380]\n",
            "Train Error: Accuracy: 41.2%\n",
            "Val Error: \n",
            " Accuracy: 41.9%, Avg loss: 1.341865 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 1.367620  [    0/20380]\n",
            "Train Error: Accuracy: 41.2%\n",
            "loss: 1.330213  [ 6400/20380]\n",
            "Train Error: Accuracy: 41.3%\n",
            "loss: 1.450954  [12800/20380]\n",
            "Train Error: Accuracy: 41.6%\n",
            "loss: 1.272157  [19200/20380]\n",
            "Train Error: Accuracy: 41.8%\n",
            "epoch over\n",
            "loss: 1.343288  [ 8904/20380]\n",
            "Train Error: Accuracy: 41.8%\n",
            "Val Error: \n",
            " Accuracy: 42.2%, Avg loss: 1.330628 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 1.351587  [    0/20380]\n",
            "Train Error: Accuracy: 41.7%\n",
            "loss: 1.320961  [ 6400/20380]\n",
            "Train Error: Accuracy: 41.7%\n",
            "loss: 1.449162  [12800/20380]\n",
            "Train Error: Accuracy: 41.8%\n",
            "loss: 1.260801  [19200/20380]\n",
            "Train Error: Accuracy: 42.1%\n",
            "epoch over\n",
            "loss: 1.326044  [ 8904/20380]\n",
            "Train Error: Accuracy: 42.0%\n",
            "Val Error: \n",
            " Accuracy: 42.9%, Avg loss: 1.320514 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 1.336855  [    0/20380]\n",
            "Train Error: Accuracy: 41.9%\n",
            "loss: 1.313079  [ 6400/20380]\n",
            "Train Error: Accuracy: 42.1%\n",
            "loss: 1.447192  [12800/20380]\n",
            "Train Error: Accuracy: 42.1%\n",
            "loss: 1.249856  [19200/20380]\n",
            "Train Error: Accuracy: 42.3%\n",
            "epoch over\n",
            "loss: 1.311179  [ 8904/20380]\n",
            "Train Error: Accuracy: 42.3%\n",
            "Val Error: \n",
            " Accuracy: 43.7%, Avg loss: 1.311324 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 1.323255  [    0/20380]\n",
            "Train Error: Accuracy: 42.3%\n",
            "loss: 1.306213  [ 6400/20380]\n",
            "Train Error: Accuracy: 42.3%\n",
            "loss: 1.444802  [12800/20380]\n",
            "Train Error: Accuracy: 42.5%\n",
            "loss: 1.239242  [19200/20380]\n",
            "Train Error: Accuracy: 42.6%\n",
            "epoch over\n",
            "loss: 1.298404  [ 8904/20380]\n",
            "Train Error: Accuracy: 42.6%\n",
            "Val Error: \n",
            " Accuracy: 44.3%, Avg loss: 1.302875 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 1.310628  [    0/20380]\n",
            "Train Error: Accuracy: 42.5%\n",
            "loss: 1.300094  [ 6400/20380]\n",
            "Train Error: Accuracy: 42.7%\n",
            "loss: 1.441841  [12800/20380]\n",
            "Train Error: Accuracy: 42.8%\n",
            "loss: 1.228903  [19200/20380]\n",
            "Train Error: Accuracy: 42.9%\n",
            "epoch over\n",
            "loss: 1.287403  [ 8904/20380]\n",
            "Train Error: Accuracy: 42.8%\n",
            "Val Error: \n",
            " Accuracy: 44.5%, Avg loss: 1.295008 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 1.298832  [    0/20380]\n",
            "Train Error: Accuracy: 42.8%\n",
            "loss: 1.294532  [ 6400/20380]\n",
            "Train Error: Accuracy: 42.8%\n",
            "loss: 1.438225  [12800/20380]\n",
            "Train Error: Accuracy: 43.1%\n",
            "loss: 1.218798  [19200/20380]\n",
            "Train Error: Accuracy: 43.2%\n",
            "epoch over\n",
            "loss: 1.277861  [ 8904/20380]\n",
            "Train Error: Accuracy: 43.0%\n",
            "Val Error: \n",
            " Accuracy: 44.9%, Avg loss: 1.287600 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 1.287745  [    0/20380]\n",
            "Train Error: Accuracy: 43.0%\n",
            "loss: 1.289396  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.0%\n",
            "loss: 1.433912  [12800/20380]\n",
            "Train Error: Accuracy: 43.3%\n",
            "loss: 1.208897  [19200/20380]\n",
            "Train Error: Accuracy: 43.5%\n",
            "epoch over\n",
            "loss: 1.269491  [ 8904/20380]\n",
            "Train Error: Accuracy: 43.3%\n",
            "Val Error: \n",
            " Accuracy: 45.4%, Avg loss: 1.280556 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 1.277268  [    0/20380]\n",
            "Train Error: Accuracy: 43.3%\n",
            "loss: 1.284597  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.3%\n",
            "loss: 1.428881  [12800/20380]\n",
            "Train Error: Accuracy: 43.5%\n",
            "loss: 1.199183  [19200/20380]\n",
            "Train Error: Accuracy: 43.7%\n",
            "epoch over\n",
            "loss: 1.262043  [ 8904/20380]\n",
            "Train Error: Accuracy: 43.6%\n",
            "Val Error: \n",
            " Accuracy: 45.5%, Avg loss: 1.273809 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 1.267324  [    0/20380]\n",
            "Train Error: Accuracy: 43.6%\n",
            "loss: 1.280072  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.5%\n",
            "loss: 1.423120  [12800/20380]\n",
            "Train Error: Accuracy: 43.5%\n",
            "loss: 1.189650  [19200/20380]\n",
            "Train Error: Accuracy: 43.8%\n",
            "epoch over\n",
            "loss: 1.255308  [ 8904/20380]\n",
            "Train Error: Accuracy: 43.7%\n",
            "Val Error: \n",
            " Accuracy: 45.7%, Avg loss: 1.267309 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 1.257861  [    0/20380]\n",
            "Train Error: Accuracy: 43.6%\n",
            "loss: 1.275777  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.6%\n",
            "loss: 1.416621  [12800/20380]\n",
            "Train Error: Accuracy: 43.9%\n",
            "loss: 1.180305  [19200/20380]\n",
            "Train Error: Accuracy: 44.0%\n",
            "epoch over\n",
            "loss: 1.249115  [ 8904/20380]\n",
            "Train Error: Accuracy: 43.8%\n",
            "Val Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.261019 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 1.248839  [    0/20380]\n",
            "Train Error: Accuracy: 43.8%\n",
            "loss: 1.271674  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.7%\n",
            "loss: 1.409384  [12800/20380]\n",
            "Train Error: Accuracy: 44.1%\n",
            "loss: 1.171165  [19200/20380]\n",
            "Train Error: Accuracy: 44.2%\n",
            "epoch over\n",
            "loss: 1.243330  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.1%\n",
            "Val Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.254911 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 1.240234  [    0/20380]\n",
            "Train Error: Accuracy: 43.9%\n",
            "loss: 1.267733  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.9%\n",
            "loss: 1.401430  [12800/20380]\n",
            "Train Error: Accuracy: 44.1%\n",
            "loss: 1.162262  [19200/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "epoch over\n",
            "loss: 1.237847  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.2%\n",
            "Val Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.248967 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 1.232028  [    0/20380]\n",
            "Train Error: Accuracy: 44.1%\n",
            "loss: 1.263923  [ 6400/20380]\n",
            "Train Error: Accuracy: 43.8%\n",
            "loss: 1.392830  [12800/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "loss: 1.153635  [19200/20380]\n",
            "Train Error: Accuracy: 44.4%\n",
            "epoch over\n",
            "loss: 1.232583  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "Val Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.243177 \n",
            "\n",
            "Epoch 31\n",
            "-------------------------------\n",
            "loss: 1.224206  [    0/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "loss: 1.260213  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.0%\n",
            "loss: 1.383742  [12800/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "loss: 1.145333  [19200/20380]\n",
            "Train Error: Accuracy: 44.4%\n",
            "epoch over\n",
            "loss: 1.227476  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.4%\n",
            "Val Error: \n",
            " Accuracy: 46.0%, Avg loss: 1.237542 \n",
            "\n",
            "Epoch 32\n",
            "-------------------------------\n",
            "loss: 1.216755  [    0/20380]\n",
            "Train Error: Accuracy: 44.2%\n",
            "loss: 1.256576  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.2%\n",
            "loss: 1.374453  [12800/20380]\n",
            "Train Error: Accuracy: 44.5%\n",
            "loss: 1.137405  [19200/20380]\n",
            "Train Error: Accuracy: 44.7%\n",
            "epoch over\n",
            "loss: 1.222481  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.5%\n",
            "Val Error: \n",
            " Accuracy: 46.1%, Avg loss: 1.232075 \n",
            "\n",
            "Epoch 33\n",
            "-------------------------------\n",
            "loss: 1.209661  [    0/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "loss: 1.252983  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.3%\n",
            "loss: 1.365388  [12800/20380]\n",
            "Train Error: Accuracy: 44.6%\n",
            "loss: 1.129893  [19200/20380]\n",
            "Train Error: Accuracy: 44.8%\n",
            "epoch over\n",
            "loss: 1.217561  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.7%\n",
            "Val Error: \n",
            " Accuracy: 46.1%, Avg loss: 1.226790 \n",
            "\n",
            "Epoch 34\n",
            "-------------------------------\n",
            "loss: 1.202901  [    0/20380]\n",
            "Train Error: Accuracy: 44.7%\n",
            "loss: 1.249407  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.5%\n",
            "loss: 1.357012  [12800/20380]\n",
            "Train Error: Accuracy: 44.8%\n",
            "loss: 1.122818  [19200/20380]\n",
            "Train Error: Accuracy: 45.0%\n",
            "epoch over\n",
            "loss: 1.212688  [ 8904/20380]\n",
            "Train Error: Accuracy: 44.9%\n",
            "Val Error: \n",
            " Accuracy: 46.2%, Avg loss: 1.221697 \n",
            "\n",
            "Epoch 35\n",
            "-------------------------------\n",
            "loss: 1.196452  [    0/20380]\n",
            "Train Error: Accuracy: 44.8%\n",
            "loss: 1.245826  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.7%\n",
            "loss: 1.349652  [12800/20380]\n",
            "Train Error: Accuracy: 45.0%\n",
            "loss: 1.116172  [19200/20380]\n",
            "Train Error: Accuracy: 45.2%\n",
            "epoch over\n",
            "loss: 1.207838  [ 8904/20380]\n",
            "Train Error: Accuracy: 45.0%\n",
            "Val Error: \n",
            " Accuracy: 46.4%, Avg loss: 1.216788 \n",
            "\n",
            "Epoch 36\n",
            "-------------------------------\n",
            "loss: 1.190283  [    0/20380]\n",
            "Train Error: Accuracy: 44.9%\n",
            "loss: 1.242222  [ 6400/20380]\n",
            "Train Error: Accuracy: 44.9%\n",
            "loss: 1.343359  [12800/20380]\n",
            "Train Error: Accuracy: 45.2%\n",
            "loss: 1.109925  [19200/20380]\n",
            "Train Error: Accuracy: 45.3%\n",
            "epoch over\n",
            "loss: 1.202984  [ 8904/20380]\n",
            "Train Error: Accuracy: 45.1%\n",
            "Val Error: \n",
            " Accuracy: 46.3%, Avg loss: 1.212043 \n",
            "\n",
            "Validation no longer rising. Done!\n",
            "Max number of epochs hit or validation stop reached. Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,loss_rec)\n",
        "plt.title('Epochs vs Loss')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Loss')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "7ab4e334-0a10-487e-8e77-68252c011119",
        "id": "v82wJ3v6RUbF"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "plt.plot(epo_rec,acc_rec)\n",
        "plt.title('Epochs vs Accuracy')\n",
        "ax.set_xlabel('Epochs')\n",
        "ax.set_ylabel('Accuracy')\n",
        "plt.locator_params(axis=\"x\", integer=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "ae9f4d87-3392-4909-cb07-ad00fafc60f5",
        "id": "DFuH_aUKRUbG"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a87ea79-f1e9-46b2-90be-94f41e0073cf",
        "id": "dN3BPLkjRUbH"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 45.5%, Avg loss: 1.224221 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How did this compare to the Feed Forward Network from HW3?\n",
        "\n",
        "\n",
        "None of the proposed networks were able to perform better than the feed forward network in the same given time span of 100 epochs, with no test accuracy in each individual experiment breaking the 81.7 accuracy benchmark set by HW3. One possible explanation is that the data is simpler and the sequence recordings are not very consistent between actions - a feed forward network looking at the data with less adjustments may need to make less considerations compared to something like an LSTM trying to review the various sequences. It is possible that RNN and similar networks are not a good fit for this problem as a result.\n",
        "\n",
        "It is also possible that there exist different and/or better hyperparameters that could have been used for each individual model - due to the LSTM issues, I was not able to test them in this experiment. I would likely return to the RNN model and test the hyperparameters again, as it showed the most promising results in terms of accuracy."
      ],
      "metadata": {
        "id": "cFNDnQzFTqDj"
      }
    }
  ]
}